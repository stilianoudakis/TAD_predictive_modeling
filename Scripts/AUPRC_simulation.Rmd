---
title: "AUPRC_simulation"
author: "Spiro Stilianoudakis"
date: "May 20, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading Libraries

```{r}
library(GenomicRanges)
library(caret)
library(data.table)
library(gbm)
library(randomForest)
library(glmnet)
library(pROC)
library(dplyr)
library(ggplot2)
library(DMwR)
library(gridExtra)
library(pROC)
library(ROCR)
library(cluster)
library(ggpubr)
library(scales)
library(GGally)
library(VennDiagram)
library(network)
library(sna)
library(gtable)
library(grid)
library(magrittr) 
library(DT)
library(tidyverse)
library(reshape)
library(ROSE)
library(lattice)
library(corrplot)
library(cluster)
library(RColorBrewer)
library(PRROC)
#library(MLmetrics)
```

# Initializing simulation

```{r}
# set of different levels of class imbalance
IR = seq(-20,-5,by=1)

##defining function to extract AUPR curve
auprcSummary <- function(data, lev = NULL, model = NULL){
  lvls <- levels(data$obs) #take the probability of good class
  prob_good <- data[,lvls[2]] 
  the_curve <- pr.curve(scores.class0 = prob_good,
                        weights.class0 = as.numeric(data$obs)-1, #provide the class labels as 0/1
                        curve = FALSE)
  out <- the_curve$auc.integral
  names(out) <- "AUPRC"
  out
}

#initializing
auprc <- numeric()
precision <- numeric()
recall <- numeric()
mcc <- numeric()
tp <- numeric()
fp <- numeric()
tn <- numeric()
fn <- numeric()
imbalance <- character()
iteration <- numeric()
resampling <- character()

for(i in 1:length(IR)){
#  for(j in 1:10){
j=1    
    #randomly generate data for classification
    set.seed(j)
    dat <- twoClassSim(n = 1000, #number of rows
                       linearVars = 10, #linearly important variables
                       noiseVars = 5, #uncorrelated irrelevant variables
                       corrVars = 5, #correlated irrelevant variables
                       mislabel = .05, #percentage possibly mislabeled
                       intercept = IR[i] #controls imbalance
                       ) 
    
    #recode the response variable
    dat$Class <- factor(ifelse(as.character(dat$Class)=="Class1", "No", "Yes"), levels=c("No", "Yes"))
    
    #split the data
    set.seed(j)
    index <- createDataPartition(y = dat$Class, p = .7, list = FALSE)
    train <- dat[index, ]
    test <- dat[-index, ]
    
    # set number of iterations
    samps = 50
    
    for(k in c("none", "ros", "rus", "smote")){
      print(paste(c(IR[i],j,k)))
      
      #perform resampling 
      if(k=="ros"){
        #assign sample indeces
        sampids <- matrix(ncol=samps, 
                          nrow=length(train$Class[which(train$Class=="No")]))
        
        #filling in the sample ids matrix
        set.seed(123)
        for(m in 1:samps){
          sampids[,m] <- sample(x = which(train$Class=="Yes"),
                                size = length(which(train$Class=="No")),
                                replace = TRUE)
        }
        train <- rbind.data.frame(train[which(train$Class=="No"),],
                                  train[sampids[,1],])
        #Randomly shuffle the data
        set.seed(321)
        train <- train[sample(nrow(train)),]
      }else if(k=="rus"){
        #assign sample indeces
        sampids <- matrix(ncol=samps, 
                          nrow=length(train$Class[which(train$Class=="Yes")]))
        
        #filling in the sample ids matrix
        set.seed(123)
        for(m in 1:samps){
          sampids[,m] <- sample(x = which(train$Class=="No"),
                                size = length(which(train$Class=="Yes")),
                                replace = FALSE)
        }
        train <- rbind.data.frame(train[which(train$Class=="Yes"),],
                                  train[sampids[,1],])
        
        #Randomly shuffle the data
        set.seed(321)
        train <- train[sample(nrow(train)),]
      }else if(k=="smote"){
        set.seed(123)
        train <- SMOTE(Class ~ ., 
                       data=train, 
                       perc.over = 100, 
                       perc.under = 200)
        
        #Randomly shuffle the data
        set.seed(123)
        train <- train[sample(nrow(train)),]
      }else{train=train}
      
      #set seeds for each cross folds
      set.seed(123)
      #length is = (n_repeats*nresampling)+1
      seeds <- vector(mode = "list", length = 11)
      #(1 is the number of tuning parameter lambda
      for(l in 1:10) seeds[[l]]<- sample.int(n=1000, 100)
      #for the last model
      seeds[[11]]<-sample.int(1000, 1)
      
      ##setting contols for elastic net
      fitControl <- trainControl(seeds = seeds,
                                 method = "cv",
                                 number = 5,
                                 ## Estimate class probabilities
                                 classProbs = TRUE,
                                 ## Evaluate performance using 
                                 ## the following function
                                 summaryFunction = auprcSummary)
      
      #set number of predictors to consider at each node
      tunegrid <- expand.grid(mtry=ceiling(sqrt(dim(train)[2] - 1)))
      
      #performing random forest
      rfModel <- train(Class~., data=train, 
                       method="rf", 
                       metric="AUPRC", 
                       tuneGrid=tunegrid, 
                       trControl=fitControl, 
                       ntree=500) #as.numeric(rownames(results)[1]))
      
      pred.rfModel <- predict(rfModel, 
                              newdata=test)
      
      confMat <- confusionMatrix(data=pred.rfModel, test$Class, positive="Yes")
      TN = as.numeric(confMat$table[1,1])
      FN = as.numeric(confMat$table[1,2])
      FP = as.numeric(confMat$table[2,1])
      TP = as.numeric(confMat$table[2,2])
      
      fg <- pred.rfModel[test$Class == "Yes"]
      bg <- pred.rfModel[test$Class == "No"]
      pr <- pr.curve(scores.class0 = fg, scores.class1 = bg, curve = F)
      
      #auprc <- pr$auc.integral
      #precision <- TP/(TP+FP)
      #recall <- TP/(TP+FN)
      #mcc <- (TP*TN - FP*FN)/( sqrt( (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) ) )
      
      auprc <- rbind(auprc, pr$auc.integral)
      precision <- rbind(precision, TP/(TP+FP))
      recall <- rbind(recall, TP/(TP+FN))
      mcc <- rbind(mcc, (TP*TN - FP*FN)/( sqrt( (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) ) ))
      tp <- rbind(tp, TP)
      fp <- rbind(fp, FP)
      tn <- rbind(tn, TN)
      fn <- rbind(fn, FN)
      #imbalance <- rbind(imbalance, IR[i])
      imbalance <- rbind(imbalance,as.numeric(table(test$Class)[2])/as.numeric(table(test$Class)[1]))
      iteration <- rbind(iteration, j)
      resampling <- rbind(resampling, k)
      
    }
#  }
}

performance_df <- cbind.data.frame(Imbalance = imbalance,
                                   Iteration = iteration,
                                   Resampling = resampling,
                                   AUPRC = auprc,
                                   Precision = precision,
                                   Recall = recall,
                                   MCC = mcc,
                                   TP = tp,
                                   FP = fp,
                                   TN = tn,
                                   FN = fn)

performance_df$Imbalance <- as.numeric(as.character(performance_df$Imbalance))

saveRDS(performance_df, "/home/stilianoudakisc/TAD_data_analysis/auprc_simulation/performance_df.rds")

```

# Plots

```{r}
ggplot(performance_df[which(performance_df$Resampling=="none"),], aes(x=Imbalance, y=AUPRC)) +
  geom_point(shape=1) +   
  geom_smooth(method=lm) +
  theme_minimal() +
  theme_bw()

ggplot(performance_df[which(performance_df$Resampling=="none"),], aes(x=Imbalance, y=Precision)) +
  geom_point(shape=1) +   
  geom_smooth(method=lm) +
  theme_minimal() +
  theme_bw()

ggplot(performance_df[which(performance_df$Resampling=="none"),], aes(x=Imbalance, y=Recall)) +
  geom_point(shape=1) +   
  geom_smooth(method=lm) +
  theme_minimal() +
  theme_bw()

ggplot(performance_df[which(performance_df$Resampling=="none"),], aes(x=Imbalance, y=MCC)) +
  geom_point(shape=1) +   
  geom_smooth(method=lm) +
  theme_minimal() +
  theme_bw()
```

