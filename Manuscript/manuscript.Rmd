---
title: Computational Prediction of Boundaries of 3D Genomic Domains in Class Imbalance
  Settings
csl: styles.ref/genomebiology.csl
output:
  word_document:
    reference_docx: styles.doc/NIH_grant_style.docx
  pdf_document: default
bibliography: References/references.bib
--- 

Spiro C. Stilianoudakis^1^ (stilianoudasc@mymail.vcu.edu), Mikhail G. Dozmorov^1\*^ (mikhail.dozmorov@vcuhealth.org)

^1^ Dept. of Biostatistics, Virginia Commonwealth University, Richmond, VA, 23298, USA  
^\*^ To whom correspondence should be addressed: Virginia Commonwealth University, Richmond, VA, 23298, 804-827-2055, mikhail.dozmorov@vcuhealth.org

# ABSTRACT

**Background.** Chromosome conformation capture sequencing technologies have shown that the three-dimensional (3D) structure of the genome is folded into distinct compartments, known as topologically associated domains (TADs) - units of coordinated gene expression. The location of TAD boundaries is highly conserved, suggesting the presence of epigenomic marks aiding in TAD formation. The ability to predict which epigenomic features are most associated with the TAD boundaries will allow for better understanding the regulatory role of the 3D structure of the genome.

Existing methods for predicting associations between genomic annotations tend to ignore key characteristics of genomic data. Specifically, when constructing the model for classification, the number of genomic regions surrounding TAD boundaries is much less than the number of other regions. This leads to heavily imbalanced classes and can result in poor performances as a model's ability to assign a new sample to a given class is influenced by the prevalence of that class in the training set. Furthermore, most methods utilize direct overlap as a means to quantify this association, while distance, the measure of spatial relationships, remains unaccounted for. 

**Methods.** We proposed a novel ensemble framework that systematically addresses those data irregularities and characteristics. Multiple random forest classification models, in combination with variations in cell line, data resolution, feature engineering, and re-sampling techniques were performed and compared. A number of performance metrics were assessed, including [??? will update when ready].

**Results.** 

**Conclusions.** 

# INTRODUCTION

The advent of various genome-wide sequencing technologies, such as high-throughput conformation capture (notably Hi-C), have revealed how the spatial organization of the human genome may affect genomic regulation [@lieberman2009comprehensive]. Analyses have shown that the genome is folded into distinct compartments termed topologically associating domains (TADs) [@dixon2012topological]. Evidence suggests that regulatory elements and genes tend to interact more frequently within the same TAD [@symmons2014functional]. Approximately 60-80% of TADs remain stable across cell types [@Schmitt:2016aa], suggesting that the boundaries of TADs may play a role in restricting the function of certain genomic elements such as enhancers, thereby impacting the transcription of genes. Furthermore, studies have shown that changing the 3D structure of the DNA, causing disruptions in these domains, can lead to adverse outcomes and diseases like cancer [@hnisz2016activation; @flavahan2016insulator]. Therefore, it has become increasingly important to be able to identify the key molecular drivers of the formation of TAD boundaries in order to further our understanding of the human genome.

The distinct patterns of epigenomic marks, binding peaks of different factors, and actively transcribed genes prompt the use of computational approaches to identify which epigenomic features are most predictive of TAD boundaries. Current methods rely on the use of classification algorithms to draw associations between the spatial relationship of functional genomic elements and regions that include TAD boundaries. Although several useful insights have been made, such as the convergent binding of CTCF [@ong2014ctcf; @ghirlando2016ctcf], many methods ignore key characteristics of domain data, such as the impact of heavily imbalanced number of boundaries vs. other regions. In a classification setting, when one is attempting to discriminate between regions with and without TAD boundaries, the class imbalance issue will contribute to small imbalance ratios (defined as the ratio of minority to majority classes[@Orriols-Puig2008]). Such heavily imbalanced datasets are known to adversely impact the performance of the classifiers as the learned model is biased towards the majority class to minimize the overall error rate [@lusa2010class;@chen2013influence;@jeni2013facing]. Consequently, careful consideration must be taken when deciding which performance metric(s) to use for evaluation of predictive models, especially in the case of imbalanced data. 

Commonly used measures of model performance for binary classifiers include threshold-free metrics like the area under the receiver operating curve (AUROC), and other threshold-specific metrics like accuracy, sensitivity, and specificity. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The subsequent AUROC, measures how well the model is capable of distinguishing between the two classes [@park2004receiver]. Accuracy is defined as the ratio of correctly identified cases (either from the positive or negative class) over the total number of cases. It measures the overall proportion of correctly classified instances. Sensitivity, also referred to as recall or TPR, is the ratio of true positives over the total number of positive classes. Specificity, on the other hand, also referred to as TNR, is the ratio of true negatives over the total number of negative classes. Each measures the proportion of correctly identified positive and negative classes respectively [@yerushalmy1947statistical]. Problems arise when using such measures in the event of imbalanced classes. For AUROC, when the prevalence of an event is low--that is, a defined genomic region truly containing a TAD boundary--mean probabilities are biased towards the majority class. This results in the area of interest under an ROC curve to be compressed toward a small corner in the ROC space [@prati2011survey]. While not directly affecting the value of the AUROC, this can have severe consequences on the interpretability of the model's performance. <!--A better threshold-free measure to use when dealing with imbalanced data is the area under the precision-recall curve (AUPRC).  The interpretation of the AUPRC of a model is similar to that of the AUROC. However, where as the baseline model performance according to the AUROC is given by 0.50, the baseline model performance according to the AUPRC is given by the ratio of true positives over the total number of cases. This enables a more realistic benchmark to evaluate a model on as this ratio will be lower than 0.5 for a test data set with imbalanced classes.--> Likewise, threshold-specific metrics like accuracy and specificity are also problematic when evaluating model performance on imbalance data due to being highly influenced by the correct classification of the majority class. Better measures to consider are composite metrics involving both precision and recall together because they soften the influence of a model's ability to correctly classify majority classes and yield more dependable and interpretable results. Therefore, measures like the F1-Score and Matthew's Correlation Coefficient (MCC) offer better interpretation, especially in the instance of imbalanced classes [@jeni2013facing]. The F1-Score can be interpreted as a weighted average of the precision and recall values, while the MCC is, in essence, the correlation coefficient between the observed and predicted binary classifications [@brodersen2010balanced]. Each metric uses all 4 quadrants of the confusion matrix, thus providing more balanced measures in the case of imbalanced data [@chicco2017ten].

<!--
, and balanced accuracy offer better interpretation, especially in the instance of imbalanced classes [@jeni2013facing]. The F1-Score can be interpreted as a weighted average of the precision and recall values, balanced accuracy measures the average accuracy obtained on either class, and MCC is, in essence, the correlation coefficient between the observed and predicted binary classifications [@brodersen2010balanced]. Each metric uses all 4 quadrants of the confusion matrix, thus providing more balanced measures in the case of imbalanced data [@chicco2017ten].
-->

<!--
Certain composite threshold-specific metrics such as balanced accuracy and Youden's Index should be preferred because they soften the influence of a model's ability to correctly classify majority classes and yield more dependable and interpretable results [@jeni2013facing]. Here, balanced accuracy measures the average accuracy obtained on either class [@brodersen2010balanced]. Informedness, also referred to as Youden's Index, measures the probability of the model making an informed decision and corresponds to giving equal weight per class, rather than to each instance like Accuracy [@youden1950index;@powers2011evaluation].
-->

<!--
Better measures to consider are composite metrics involving both precision and recall together. Therefore, measures like the F1-Score, Youden's Index (YI), and Matthew's Correlation Coefficient (MCC) offer better interpretation, especially in the instance of imbalanced classes [@jeni2013facing]. The F1-Score can be interpreted as a weighted average of the precision and recall values, while Youden's index is interpreted as the arithmetic mean between sensitivity (recall) and specificity. MCC is, in essence, the correlation coefficient between the observed and predicted binary classifications. Each metric uses all 4 quadrants of the confusion matrix, thus providing more balanced measures in the case of imbalanced data [@chicco2017ten].
-->

In addition to employing suitable metrics for evaluating models validated on imbalanced data, there also exist several algorithmic or data level solutions. Algorithmic level solutions involve modifyng existing classifiers in order to curtail the bias induced by imbalanced classes [@estabrooks2004multiple; @chawla2003smoteboost; @chen2004using; @khoshgoftaar2007empirical]. Data level solutions, on the other hand, mostly constitute as resampling techniques, in which random sampling is used to either replicate or remove data points in order to create a more balanced dataset [@chawla2004special; @chawla2009data]. It has been shown that quite simple resampling techniques can drastically improve model performance in the face of imbalanced data [@japkowicz2002class; @dubey2014analysis]. For the purposes of this study, we focus our attention toward data level solutions so that all results may be classifier-independent, and, thus, more easily comparable. 

Another underexplored aspect of modeling the association between TAD boundaries and genomic annotations is the various types of relationships between them. Typical approaches include overlap counts or percents [@mourad2016computational; @hong2017computational; @huang2015predicting]. Counts refer to the number of times a genomic annotation directly overlaps with a TAD boundary region, e.g., a TAD boundary may overlap with several ChIP-seq peaks for a given transcription factor. Percents refers to the percent of overlap of a genomic annotation with a TAD boundary region, e. g., a 60% of a TAD boundary may overlap genomic region annotated as heterochromatin. 

While direct overlaps represent the most straightforward measure of functional associations, they do not account for indirect relationships shown to be one of the major driving force of genome regulation [??? REFS]. The most prominent example being the enhancer-promoter relationships, where enhancers are frequently located hundreds or thousands of bases away from their target promoters [??? REFS]. The use of distances between TAD boundaries and genomic annotations has largely been ignored. However, these distance features have the potential to offer a more accurate spatial representation of which genomic features are associated with TAD boundaries.

Additionally, model performance is heavily contingent upon the resolution of the contact matrix used to identify the location of TADs throughout the genome. It is often unclear from previous studies what resolution contact matrices were used when retrieving TAD boundaries, and how other resolutions would affect their results. A lower resolution contact matrix will result in the identification of larger-sized TADs, and subsequently, less TAD boundary points. This will contribute to smaller sample sizes and could effect predictive performances. 

In this study, we have developed an ensemble framework for predicting TAD boundaries in order to systematically compare many data driven solutions used to address the issues presented above. We evaluated Hi-C data for both the GM12878 and K562 cell line obtained at 10 kb, 25 kb, 50 kb, and 100 kb resolution. For each resolution, we examined the inclusion of three different predictor types, including distance as the measure of association between genomic elements. We then tested four different re-sampling techniques aimed at creating balanced classes. Noninformative features were removed using a feature reduction algorithm and random forest classifications were performed to assess model performance, and investigate which genomic annotations were most associated with the TAD boundaries for a given system from the complete ensemble.  Model performance was evaluated using AUROC, AUPRC, F1-Score, and MCC. 

# METHODS

## DOMAIN DATA

Replicate Hi-C data for the GM12878 and K562 cell lines were downloaded from GEO GSE63525 [@rao20143d] (Supplementary Table 4). The autosomal genomic coordinates (GRCh37/hg19 human genome assembly) of TAD boundaries were obtained from data at 10 kb, 25 kb, 50 kb, and 100 kb resolution using the Arrowhead algorithm [@durand2016juicebox]. The start and end coordinates of all TADs were concatenated, sorted, and unique TAD boundary points were obtained. 

## GENOMIC ANNOTATION DATA

Genomic annotation data in the form of cell type specific chromatin states, histone marks, and transcription factor binding sites (GRCh37/hg19 human genome assembly) were obtained from the UCSC Genome Browser Database [@Tyner:2017aa] (Supplementary Table 1).


## MODEL CONSTRUCTION

To establish the data for modeling, the genome was binned into equally sized intervals defined by the data resolution for the corresponding contact matrix (Figure 1). For example, for domain data obtained from a 10 kb resolution contact matrix, the genome was binned into 10 kb intervals. For the boundary data, in order to accommodate for the uncertainty in exact boundary location, the boundary points were flanked on both sides by the size of the resolution of the corresponding contact matrix. For example, for 10 kb data, each uniquely identified TAD boundary was flanked on either side by 10 kilobases for a total width around each boundary point of 20 kb. A genomic bin was labeled as having a TAD boundary within it (Y=1) if it overlapped with a particular flanked boundary. Otherwise, the bin was labeled as not containing a boundary (Y=0).

## ENSEMBLE FRAMEWORK

An ensemble of models was established for the purposes of systematically comparing the performances of different parameters in the framework (Figure 2). Each system in the framework is assumed to be composed of a model constructed from a particular data resolution, with a particular predictor type for the feature space.

The data sets used for modeling were composed of the full set of genomic bins that either overlapped with a flanked TAD boundary or did not. These two classes made up the minority and majority sets respectively. The data was then split into a 7:3 ratio of training to testing sets. Each training and testing set was composed of a similar majority to minority class ratio as the full data set. For the task of performance evaluation and prediction, the test set remained constant for all ensemble systems to account for an unbiased comparison.

### FEATURE ENGINEERING AND RE-SAMPLING

Using the sets of genomic annotations, we created three types of predictors that were used as features for subsequent models to analyze their respective spatial relationship with TAD boundaries (Figure 3):

1. **Overlap Counts (OC)**: For each genomic bin, the total number of instances where a genomic bin overlapped with regions assigned to genomic annotations (features) was calculated. In the case of no overlaps, the value was set to 0.
   
2. **Overlap Percent (OP)**: For each genomic bin, the percent of overlap between the width of the region assigned to a genomic annotation and the total width of the bin was calculated. We defined the feature width as the number of bases that overlapped with a particular genomic bin. The percent was then calculated by dividing the feature width by the bin width. If multiple overlaps existed, the feature width was defined as the sum of the total number of bases that overlapped with a particular bin. Note that the bin width remained constant for a given resolution (either 10 kb, 25 kb, 50 kb, or 100 kb). Values for bins with no overlaps were set to be 0.

3. **Log2 Distance**: For each genomic bin, the $log_{2}$ of the distance in bases (refered to hereafter simply as $\textit{distance}$), from the center of the bin to the center of the nearest region defined by a specific genomic annotation was calculated. The log transformation was used as a normalization technique in order to account for the skewness of the data (Supplementary Figures 1).

In order to assess the influence of imbalanced classes, we then evaluated four re-sampling techniques (in addition to no re-sampling), composed of data from each predictor type. Each re-sampling technique is described in detail below.

1. **No Sampling**: All of the data points from the majority and minority class of the training set were used.

2. **Random Under-Sampling (RUS)**: All of the minority classes from the training set were used. Sampling without replacement was used to obtain the same number of the majority classes. 

3. **Random Over-Sampling (ROS)**: All of the majority classes from the training set were used. Sampling with replacement was used to obtain the same number of the minority classes. 

4. **SMOTE** (Synthetic Minority Over-Sampling Technique): This method incorporates both random under- and over-sampling. Under-sampling is performed without replacement from the majority class, while over-sampling is performed by creating new synthetic observations using the minority class [@chawla2002smote]. The `DMwR` R package was used to perform SMOTE (version 0.4.1). 

<!--
5. **ROSE** (Random Over-Sampling Examples): Similar to SMOTE, ROSE combines techniques of over-sampling and under-sampling. However, contrary to SMOTE, all of the data generated by ROSE is synthetic. The data is created by sampling from one of the two classes, then generating a new example in its neighborhood using a smoothed bootstrap approach. The shape of the neighborhood is determined by the kernel density estimate of the two classes [@lunardon2013r]. Another important distinction between ROSE and SMOTE is that, for ROSE, the creation of perfectly balanced classes is unlikely due to the randomness in sampling between the two classes. The `ROSE` R package was used to perform ROSE (version 0.0.3).
-->

### FEATURE REDUCTION

A regularization technique using a combination of the $l_{1}$ and $l_{2}$ penalties, known as the elastic-net, was used to reduce the feature space. The elastic-net was chosen in order to suitably reduce the feature space while also maintaining the inclusion of multiple correlated predictors. For each elastic-net regularization, 10-fold cross-validation was used to tune the parameters that controlled the penalty terms. All elastic-net algorithms were implemented in R using the `caret` package version 6.0 [@kuhn2012caret].

<!--
Recursive feature elimination (RFE) was then used to determine the optimal number of features for models with the best performing predictor type. For each set of predictor type, random forest models were performed recursively on subsets of the feature space. The specific subsets of features were chosen as powers of 2 for computational efficiency. Model performance for each subset was evaluated using AUPRC. The optimal set of featues to include in downstream analyses was determined to be the subset in which the AUPRC leveled off. Again, to confirm that results were consistent, the reduction process was repeated for each combination of re-sampling technique, resolution, and cell line. 
-->

### FINAL MODEL ASSESSMENT AND PERFORMANCE

Once the appropriate predictor type and set of features were determined, a final set of random forest classification models were performed to fully compare re-sampling techniques. To reduce bias due to random dataset generation, 10-fold cross validation was used <!--to tune the number of features to consider at each node and the number of ensemble trees to aggregate-->.The default number of features to consider at each node of the random forest algorithm was set as the square root of the number of features in the model. Likewise, the number of ensemble trees to aggregate was set at 500. All random forest algorithms were implemented in R using the `caret` package version 6.0 [@kuhn2012caret]. Once the model was implemented, it was assessed using the test set, and performance metrics were recorded. 

The efficacy of each re-sampling technique was compared using composite metrics including F1-score and MCC. These metrics are defined as follows:

$$F1 - Score = \frac{2TP}{2TP + FP + FN}$$

$$MCC = \frac{TP \times TN - FP \times FN}{\sqrt{ (TP + FP)(TP+FN)(TN+FP)(TN+FN) }}$$
<!--
$$Balanced \quad Accuracy = \dfrac{1}{2}\left( \dfrac{TP}{TP+FN} + \dfrac{TN}{TN+FP} \right)$$
-->

<!--
$$Informedness = \dfrac{TP}{TP+FN} + \dfrac{TN}{TN+FP} - 1$$
-->

Here, TP refers to the number of bins correctly identified as containing a TAD boundary (true positives), FP refers to the number of bins incorrectly identified as containing a TAD boundary (false positives), TN refers to the number of bins correctly identified as not containing a TAD boundary (true negatives), and FN refers to the number of bins incorrectly identified as not containing a TAD boundary. Each of these quantities are obtained from the confusion matrix created by validating the model on the testing set. <!--Additional threshold-free metrics where also reported including the AUROC and AUPRC.--> Lastly, for the task of identifying the genomic annotations that were most predictive of the formation of TAD boundaries, we ranked the variable importances associated with each feature of the ensemble system-specific random forest model. <!--To calculate variable importances for each model, the F1-Score on the out-of-bag portion of the data within each tree was recorded. Then the same was done after permuting each predictor variable. The difference between the two AUPRC values was then averaged over all trees, and normalized by the standard error of the differences.--> Annotations with low rankings correspond to functional epigenomic features that are either positively or negatively enriched near TAD boundaries, and thus, better allow the model to discriminate between genomic bins that overlap with flanked TAD boundaries.

# RESULTS

## ENSEMBLE COMPARISONS

Multiple random forest classification algorithms were built on domain data extracted from Hi-C data for 2 cell lines $C = \{GM12878, K562\}$, at four different resolutions $R = \{\text{10 kb}, \text{25 kb}, \text{50 kb}, \text{100 kb\}}$. For each classifier, we compared model performances using 3 separate predictor types $P = \{\text{OC}, \text{OP}, \text{Distance}\}$ and 4 class balancing techniques $B = \{None, RUS, ROS, SMOTE\}$. A system produced from the ensemble framework was defined as: $S = \{c, r, p, b\}$, where $c \in C$, $r \in R$, $p \in P$, and $b \in B$. Letting $|X|$ denote the cardinality of each set, we evaluated $|C| \times |R| \times |P| \times |B|$ different ensemble systems, totaling $96 (= 2 \times 4 \times 3 \times 4)$ separate models. 

## IMBALANCE RATIOS REMAINED SEVERE AND CONSISTENT ACROSS RESOLUTIONS

We examined the class imbalance of the different data resolutions for each cell line. As expected, the total number of genomic bins decreased as resolution decreased (Figure 4A). Specifically, at lower resolutions, the linear genome was binned into larger units, thereby creating fewer bins. The imbalance ratios, however, remained relatively stable and consistent across resolutions and cell line (Figure 4B). We found that there was an average IR of 0.154 (SD=0.022) and 0.137 (SD=0.0181) across resolutions for the GM12878 and K562 cell lines respectively. Here, the low imbalance ratios indicated a wide disparity between the number of genomic bins that overlap with a flanked TAD boundary and the much larger number that did not. 

## HIGH CORRRELATIONS IMPLY COLOCALIZATION OF MANY ANNOTATIONS AROUND TAD BOUNDARIES

By isolating flanked TAD boundaries and, in turn, counting the instances in which annotations overlapped with boundary regions, we were able to assess the correlations of genomic annotations and determine which annotations were enriched together at boundaries. Clustered correlograms for known colocalized annotations showed that distinct groups of transcription factors were highly positively correlated in both cell lines, and across resolutions, including CTCF, ZNF143, RAD21, and SMC3ab (Supplementary Figures 2-9). Likewise, combinations of particular histone modifications and chromatin states were also shown to exhibit similar profiles near TAD boundaries including H3K4me1, H3K4me2, and H3K4me3, as well as strong and weak enhancers. Furthermore, particular chromatin segmentation states, inclduing heterochromatin, repressed chromatin, poised promotors, and repetitive copy number variations, were found to be highly positively inter-correlated, yet were negatively correlated with many transcription factor binding sites. Notably, correlations among annotations were found to increase as resolutions decreased for both cell lines. This indicated that TAD bounardies called, and subsequently flanked, at lower resolutions tended to encapsulate more of these epigenomic marks and contribute to higher levels of enrichment. 

<!--
The high correlations among many of the genomic annotations gave precedent for the use of an elastic-net regularization algorithm in order to suitably reduce the feature space while retaining possibly correlated annotations that could be predictive of TAD boundary formation. 
-->

## CLASS IMBALANCE SEVERELY IMPACTS PERFORMANCE AMONG ALL CLASSES OF MODELS

We first evaluated performances for models implemented using OC predictor types, without re-sampling, as these characteristics represented models with the least granularity and could act as a baseline. In evaluating such composite metrics like F1-Score and MCC, we found that these models exhibited poor performances across resolutions, for both cell lines (Figure 5A). Furthermore, at some resolutions , the F1-Score and MCC could not be determined given by the model's complete inability to correctly classify any genomic bins that overlapped with flanked TAD boundaries in the test data, thereby resulting in 0 true positives <!--, as can be seen by the missing red points-->. When including OP perdictor types in the models, coupled with no resampling, we found that performances were worse than when using OC predictor types (Figure 5B). As with OC predictor types, these models were also not able to yield F1-Scores and MCCs at the 50 kb and 100 kb resolution for the GM12878 cell line or any resolution lower than 10 kb for the K562 cell line. Models built on distance-type predictors, however, exhibited slightly better performances than the other two types, yet still yielded missing or low F1-Scores and MCC at lower resolutions (Figure 5C). Models built on 100 kb resolutions were not able to yeild F1-Scores for either cell line. This indicated that the key driver leading to poor performances was not due to feature engineering, but instead the severity in the class imbalance.
<!--Mention AUC is not good metric using supplementary table-->


## DATA RE-SAMPLING IMPROVED PERFORMANCE AMONG ALL CLASSES OF MODELS 

Comparisons of the effects of the various resampling techniques were then made. When models were built on randomly oversampled data, we found a substantial increase in F1-Score and MCC for both cell lines (Figure 5 D-F). The biggest improvement in performance was seen at the 10 kb resolution, with a sharp downward trend as resolutions decreased. Although performances were low at lower resolutions, both F1-Scores and MCC values were able to be obtained, contrary to models built on completely unbalanced data as seen before. Distance-type predictors were found to offer the highest F1-Scores and MCCs for randomly oversampled data, across all resolutions and for both cell lines.

Further improvement in performance was found when models were implemented on both randomly undersampled (Figure 5 G-H) and SMOTE resampled data (Figure 5 J-K). Although the differences in performance between the two techniques were marginal, SMOTE resampled data was found to yield the best F1-Scores and MCCs among all classes of models develeped and compared in the ensemble framework. These results imply that a best performing model, one that is able to best discriminate between genomic bins that are near versus far away from TAD boundaries, is one that incorporates both random under- and over-sampling, as SMOTE is known to do.

## DISTANCE-TYPE PREDICTORS PROVIDED THE MOST INFORMATIVE SPATIAL REPRESENTATION OF EPIGENOMIC ANNOTATIONS ASSOCIATED WITH TAD BOUNDARIES

Regardless, of resampling technique however, the inclusion of distance type predictors resulted in better F1-Scores and MCCs when compared to either OC or OP predictor types. This was consistent across all resolutions, for both cell lines. Furthermore, in the best overall model (SMOTE with distance-type predictors) we found that the degradation in model performance as resolution decreased was much more pronounced in the K562 cell line.  on the GM12878 cell line, there was a slight improvement in F1-Score for the 25 kb resolution, followed by a steep decline at 50 kb. Then, both F1-Scores and MCCs showed a momentary increase in performance at the lowest resolution considered in the study. Performances from the K562 cell line degraded much faster as resolution decreased, the worse being at the 100 kb resolution.

## VARIABLE IMPORTANCES FROM TOP PERFORMING MODELS CONFIRMED BIOLOGICAL FUNCTIONALITY OF KNOWN GENOMIC ANNOTATIONS

Lastly, we investigated which genomic annotations were most predictive of TAD boundary formation. Looking at heatmaps of variable importances provided by the random forest classifiers implemented on SMOTE re-sampled data, with distance-type predictors, we found that known transcription factors associated with the hypothesized loop extrusion model [@fudenberg2016formation; @alipour2012self] were give high predictive importance in the model for both cell lines (Figure 6 A-B). These tended to include the SMC3ab, ZNF143, CTCF, and RAD21 transcription factor binding sites and were found to be ranked consistly across resolution. Other annotations known to be associated with gene regulation and affect structural properties of chromatin, such as the YY1 and MAZ transcription factors, as well DNAse hypersensitive sites, regions of heterochromatin, and the H3k27 trimethylation and H3K4me1 modifications were less consistently ranked across resolutions for either cell line. Moreover, the ranking profiles of genomic annotations were found to be more similar between the 10 kb and 25 kb resolutions, as well as between the 50 kb and 100 kb resoluions.

<!-- IN PROGRESS
# DISCUSSION

We developed an ensemble framework to systematically compare model performances for different combinations of class balancing and feature engineering techniques aimed aimed at determining a consensus approach to predicting TAD boundary formation using genomic annotations

Although we were not able to draw direct comparisons between the GM12878 and K562 cell lines, given that they did not contain the same list of cell type specific annotations, we did find that there was relative agreement in rankings of the top 5-7 predictors. However, there were notable exclusions from each cell line, in addition to inconsistencies across resolutions

## LIMITATIONS

Many elastic-net models using overlap count or percent predictors were reduced to ridge, or near-ridge regression models at higher data resolutions by having the $alpha$ penalization term tuned to 0 in the cross-validation step, thereby not reducing, or reducing very few of the feature space. The results of the variable reduction step imply that far more information relating annotions to TAD boundaries is encoded in the distance-type predictors. That is, the elastic-net algorithms were better able to separate noise and reduce the feature space when performed on distance-type predictors. Likewise, this reduction was most efficient at more refined levels of data resolution.
-->

# Abbreviations


# Acknowledgements

_Conflict of Interest._ None.

# Funding

# References
