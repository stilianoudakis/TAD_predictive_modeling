---
title: "Predictive modeling using genomic annotations"
subtitle: "Pitfalls and Recommendations"
author: "Spiro Stilianoudakis"
date: "August 9, 2018"
header-includes:
    - \usepackage{setspace}\doublespacing
    - \usepackage{amsmath}
output: 
  pdf_document:
    toc: yes
  word_document:
    fig_caption: yes
    fig_height: 3
    fig_width: 2
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ABSTRACT

###Background 
Chromosome conformation capture sequencing technologies have shown that the three-dimensional (3D) structure of the genome is folded into distinct compartments, known as topologically associated domains (TADs) - units of coordinated gene expression. The location of TAD boundaries is highly conserved, suggesting the presence of epigenomic marks aiding in TAD formation. The ability to predict which epigenomic features are most associated with the TAD boundaries will allow to better understand the regulatory role of the 3D structure of the genome.

Existing methods for predicting associations between genomic elements ignore key characteristics of the data. Specifically, the number of TAD boundaries is much less than the number of other genomic regions, leading to heavily imbalanced classes. Furthermore, most methods utilize direct overlap as a means to quantify the association, while distance, the measure of spatial relationships, remains unaccounted for. Consequently, distances on a genomic scale vary widely, leaving uncertainty how the heavily right-tailed distribution of distance measures will affect the modelâ€™s performance.


###Methods 
We propose a novel data pre-processing pipeline that addresses those shortcomings. It includes an elastic-net regularized classification model, where the mixing proportion, $\alpha$, and the penalization parameter, $\lambda$, are tuned for over a grid of values. A number of classifier performance metrics was assessed, including the F1 measure and Matthew Correlation Coefficient (MCC).

###Results 
Data preprocessing (log2-transformation and standardization) improves the performance of the models. The elastic-net model outperformed multiple logistic regression models, with and without LASSO-regularized coefficients. Likewise, the variable importance of the elastic-net yielded more stable and biologically meaningful results compared to the variables selected by the multiple logistic regression models.

###Conclusions 
Current methods used to model the epigenomic features associated with TAD boundaries are not robust to handle properties of genomic data. Models applied to unprocessed data can have poor predictive performances. Typical performance assessment metrics, such as AUROC, can mask poor performance of the models; thus, the use of more balanced metrics, such as F1 and MCC, is warranted. The elastic-net model, with its dual use of the $l_1$ and $l_2$ regularization terms allows for both the removal of uninformative predictors, while being able to handle multiple correlated epigenomic features. Our model results in better performances and more accurate identification of important features associated with the formation of TAD boundaries.

# INTRODUCTION

The advent of various genome-wide sequencing technologies, such as high-throughput conformation capture (notably Hi-C), have revealed how the spatial organization of the human genome may affect several epigenetic functions (Aiden et al.). Analyses have shown that the genome is tightly compacted into distinct compartments.  There exist regions within these compartments that have been shown to be highly conserved and self-interacting, and termed topologically associating domains (TADs) (Dixon et al.). Evidence suggests that regulatory elements and genes tend to interact more frequently within the same TAD (Symmons et al.). This suggests that the boundaries of TADs may play a role in restricting the function of elements such as enhancers, thereby impacting the transcription of genes. Furthermore, changing the 3D structure of the DNA and distrupting these domains can lead to adverse outcomes and diseases like cancer. Therefore it is important to be able to identify the key molecular drivers of the formation of TADs in order to further our understanding of the human genome.

The mechanisms underlying the formation of TADs are a complex and active area of research. Recently, it has been discovered that insulator sequences have a primary role in orchestrating the topological arrangement of higher-order chromatin architecture (Phillips-Cremins et al). Insulators are multi-faceted regulatory sequences that moderate a variety of genomic processes including activation, repression, and enhancer blocking. Specifically, the insulator binding protein CTCF has been found to be enriched at the boundary sequences of topologically associating domains in human cells and may therefore act as a mediator of long range chromatin contacts (Zuin et al.). Other regulatory elements like DNase I hypersensitive sites, the H3K36 trimethylation, and transcription factors such as ZNF274 and YY1 have been more frequently observed at TAD boundaries than in other regions (Hong et al). These have been found to be associated with more open chromatin which alter the accessibility of genes for transcription. The distinct patterns of some of these different proteins and functional elements point toward the opportunity of computational approaches in predicting the development of TAD boundaries, which, in genereal, will allow us to better understand what leads to their formation. 

Due to the size of Hi-C data and the abundance of available genomic features, few methods have been developed to study the role and interplay of different sets of these features on the folding of DNA. Furthermore, many accepted methods ignore key characteristics of the data that, when addressed, may improve predictive performances. One such pitfall is the issue of highly imbalanced classes. The commonality between most accepted methods for predicting TAD boundaries considers binning the genome and labeling the bins as either containing a TAD boundary or not. However, due to the sparcity of TADs throughout the genome, most bins will not contain a TAD boundary. This will contribute to highly imbalanced classes and will also introduce predictors with near-zero variance. It has been shown that imbalanced classes can result in poor predictive performances of classification algorithms and unless the class imbalance is mild, researchers should always use an appropriate method for dealing with this (Blagus et al).  Furthermore, the inclusion of predictors with near-zero variance can add unnecessary noise to the model and decrease computational efficiency of predictive algorithms. Another problem lies in identifying which positional characteristics of the genomic features will optimize prediction. It is unclear if distances or overlaps between genomic bins and regions of functional elements contain the most information and will lead to better predictive performances. Lastly, given that some features tend to colocalize near TAD boundaries, most predictive models may be unable to identify the complete set of features most associated with boundary formation. This can lead to less informative results and restrict our knowledge of how these genomic elements correlate with eachother.

In a previous study (Mourad et al) both a multiple logistic regression model and a LASSO regularized regression model were applied to a wide array of architectural proteins from the GM12878 cell line to predict TAD boundaries. The set of features consisted of whether or not the coordinates of a functional element overlaped with a particular genomic bin (yes or no). In the case of a partial overlap, a percentage of overlap was used. However, the class imbalance issue was not addressed and neither model used is suited to handle multiple correlated predictors. Additionally, ROC curves and AUCs were used to evaluate model performance, which is problematic, especially for highly imbalaned classes (Hanczar et al). A better indicator of predictive performance with classification algorithms is to consider the F1 score and Matthew's Correlation Coefficient (MCC). In another study (Huang et al), a more robust model in the form of a Bayesian Additive Regression Trees (BART) model was used. The set of features consisted of a score that averaged the number of sequence reads for each functional element over a particular bin for the GM12878 cell line. Here, the class proportion was manually created by dividing the positive and negative classes into two equal subsets used for model training and testing. However, it is unclear what balancing technique was used. In addition to this, the model was only performed on a small set of histone marks while ignoring wider classes of epigenomic elements. Lastly, in a more recent study (Hong et al), a bayesian rigde regression model was iteratively used on a set of transcription factor binding sites, transcription start sites, and DNase I hypersensitive sites from the hESC cell line until the best combination of features led to the optimal prediction of TAD boundaries.  Here, the features of the model consisted of the number of occurences of each genomic element within each genomic bin. Balanced classes were manually created by randomly sampling from the set of bins that did not contain a TAD boundary. Given the structure of the search algorithm proposed, though, it can be computationally inefficient to have to iterate through a large set of genomic features to find the particular set that contributes to the best prediction. Because of that, only a maximum set of 10 genomic features were considered at any given time. 

The types of models and the feature characteristics used in the aforementioned methods vary considerably. Because of the different cell lines available for analysis and the widening list of functional genomic elements, it can be quite useful to have a unified approach in predicting the formation of TAD boundaries. Therefore, in this study we have developed a novel data pre-processing pipeline that addresses the irregularities in the TAD boundary data provided by contact matrices at different resolutions for two cell lines, GM12878 and K562. We then performed a variety of machine learning algorithms on the pre-processes data to identify the genomic elements that were most predictive of TAD boundaries. In our models we incorporated the distances from bin to region as features. We found that the models performed on our pre-processed data performed better than previously established methods. Additionally, we were able to confirm that the cis-regulatory elements like insulators and promotors were highly predictive of TAD boundaries. The specific transcriptional repressor, CCCTC-binding factor (CTCF) was found to be highly predictive of TAD boundaries. Other non-transcription factor sites like DNase I hypersensitive sites and certain histone modifications like H3K36me3 were also found to be better predictors.  Our findings confirm that models with pre-processed data and distance-related genomic features not only perform better, but are also able to correctly identify a range of different functional genomic elements associated with the formation of TAD boundaries. This knowlege will allow us to gain better insight into the role that the spatial organisation of the human genome has on gene regulation. 

 

# METHODS



## THE DATA

Publicly available topologically associating domain data was obtained from GEO with accession GSE53525 for the GM12878 and K562 cell lines.  The domain data was constructed from in situ Hi-C contact matrices at a 5kb and 10 kb resolution for the GM12878 and k562 cell lines respectively. The Arrowhead algorithm was used to identify TAD boundaries for a given contact matrix (Rao et. al). Identified TAD boundaries were represented by their genomic coordinates (hg19 human genome assembly), including chromosome, start and end coordinates. The start and end coordinates were concatenated, sorted, and unique coordinates representing unique TAD boundaries were obtained [??? Check for accuracy; !!! what do you mean by accuracy here?]. A depiction of the data is presented in Figure X.

The establishment of the data for modeling first consisted of binning the genome into equal sized intervals. This was performed at the same resolution as the respective cell line. That is, for GM12878, 5 kb genomic bins were used, while 10 kb bins were used for K562. Next, for the domain data provided by GM12878, the boundary coordinates were flanked on either side by 5 kb. For the K562, the boundary coordinates were flanked by 10 kb. In either case, a genomic bin was labeled as having a TAD boundary within it (Y=1) if it overlapped with a particular flanked boundary. Otherwise, the bin was labeled as not containing an boundary (Y=0) (Figure X).

## GENOMIC ANNOTATIONS

Annotation data was obtained from the Encyclopedia of DNA Elements (ENCODE) Consortium.  These annotations consisted of genomic coordinates and were used to build the feature space, X = {$X_{1}$, . . ., $X_{p}$}, of the subsequent models. A full list of the genomic elements is provided in Table X. For each genomic element, the distance from the center of a genomic bin to the center of the nearest region (in base pairs) was calculated and included in the model.  If the center of the region given by a particular functional element was located within a genomic bin, then the distance was given to be 0. Additionally, a variable denoting the number of overlaps between a genomic bin and region representing a genomic element was totaled and included in the model (Figure X).


## DATA PIPELINE

We developed a pipeline that systematically evaluates the problems associated with TAD boundary data in a predictive modeling setting (Figure X). The pipeline was used to address issues related to normalization of predictors, class imbalance, and variable reduction. Prior to initiating the pipeline, predictors with near-zero variance were removed. To identify said predictors, the nearZeroVar function in the CARET package was used. The function considers two metrics. First, the ratio of the most frequent value over the second most frequent value was calculated. Ideally, this ratio would be close to one for well-behaved predictors. Next, the number of unique values divided by the total number of samples multiplied by 100 was calculated. Here, if the frequency ratio was greater than 20 and the percentage of unique values was less than 10, the predictor was flagged as having near-zero variance and removed. 

At each subsequent stage in the pipeline, Elastic-Net models were performed and performance metrics such as F1 scores and MCCs were evaluated. The Elastic-Net model was used here because of its ability to be tuned and its computational speed relative to other machine learning algorithms. To avoid overfitting and more accurately assess performance, 10-fold cross validation was used for all models. For each elastic-net model the mixing parameter, alpha, was tuned over a grid of 10 evenly spaced values from 0 and 1. The penalty term, labmda, was tuned over a grid of 100 evenly spaced values from 0.01 to 100.


### NORMALIZATION

Distances on a genomic scale are frequently highly skewed. In order to correct for this, a log base 2 transformation was considered. Additionally, the predictors were standardized to have unit variance in order to be able to directly compare magnitudes of parameter coefficients.


### CLASS IMBALANCE

When binning the genome, the sparcity of TAD boundaries through the genome contributed to heavily imbalanced classes. That is, proportionally, only a small number of genomic bins overlapped with a flanked TAD boundary. To assess this issue, two methods were used. The first consisted of incorporating the SMOTE command from the DmWR package in R. SMOTE stands for Synthetic Minority Over-sampling Technique. The SMOTE algorithm incorporates both under-sampling (percent under) of the majority class and over-sampling (percent over) of the minority class. The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the k minority class nearest neighbors (here, k=5). Then, the majority class is under sampled by taking a random sample that matches some pre-specified percentage of the updated minority class. It is important to note that using a combination of 100/200 (percent over/percent under-sample) will always result in perfectly balanced classes. A total of four different combinations of percent over and under-sampling were used which included: 100/200, 200/200, 300/200, and 400/200. As mentioned before, the 100/200 combination created balanced classes, while the others create an unbalanced dataset with the negative class as the majority to reflect the proportionality of the classes in the original data. The second method involved iteratively under-sampling 100 time from the majority class to match the number in the minority class. For each sample, an elastic-net model was tuned and evaluated. Then row-wise means of the performance metrics for each of the 100 interations were taken to evaluate the models (Figure X). 

### VARIABLE SELECTION

Due to the large number of genomic features included in the model, different variable selection techniques were evaluated in order to prevent overfitting, improve computational speed, and eliminate uninformative variables. There were three different wrapper methods that were used here, forward, backward, and stepwise selection. A null model consisting of just an intercept term and a full model, including all features, were specified for each selection technique. For all three, a logistic regression model was performed, and the AIC of the fitted model was used to establish which variables to include. That is, only a reduction in the model's AIC contributed to the inclusion of a feature in the model. For each technique, prior to model selection, balanced classes were iteratively created 100 times by random under-sampling from teh majority class. At each iteration the variables selected from each technique were recorded. The final set of predictors selected for each technique were those that appeared over 90% of the time accross all iterations. The union of the three sets of features from each of the techniques was obtained and used as the final feature space of the data (Figure X)

## FINAL MODEL

Once the pipeline produced the appropriate dataset, a random forest algorithm was used to assess which genomic features that were most predictive of the development of TAD boundaries. The algorithm was run iteratively over 100 bootstrap samples, each time producing sensitivities, specificities, AUCs, and variable importances. For each iteration, the model was tuned on the best number of predictors to subset as well as the optimal number of trees to use. At the end of the 100 iterations, row wise means were performed to aggregate the model performances. We then compared the random forest model to both the MLR model and the MLR model with LASSO estimated coefficients that was proposed by Mourad et al.


# RESULTS


There was a total of 247632 genomic bins that made up the response vector Y, 1629 (0.7%) of which contained TAD boundaries (Y=1). A total of 68 genomic features were included in the analysis. Two predictors were included for every feature (one binary, one continuous), making for a total of 136 predictors.  The list of predictors is provided in Table X. The feature space was reduced to 90 after all near-zero variance predictors were removed. The predictors that were removed are listed in Table X [??? Mark them in supplementary table of all features]. 

Figure X presents the model performance metrics of the eight different SMOTE combinations. The SMOTE combination utilizing percent over of 100 and percent under of 200 yielded the largest AUC (0.794). This was to be expected since this combination created perfectly balanced classes. However, looking at Figure X, the method using 100 bootstrap sample performed better than then model using SMOTE with an AUC of 0.809. Thus, it was concluded that using bootstrap samples would be more efficient moving forward. 

The best normalization technique was found to be the model that included a log base 2 transform with no standardized predictors. The AUC was found to be 0.809 and presented in Figure X. We see that this value is only marginally greater than the model using a log base 2 transform and standardized predictors. However, from Figure X, we see that the variable importance plot associated with a log base 2 transform with no standardized predictors (top right) yielded more accurate results than all other combinations. Notably, the insulator, CTCF, and DNaseI features are located in the top 3 most important features for predicting TAD boundaries, as expected. This is in contrast to the other three combinations, which presented conflicting results. Thus, it was concluded that only performing a log base 2 transformation was necessary. 

The best performing variable selection technique was found to be forward selection (AUC: 0.810) as shown in Figure X. All of the stepwise procedures performed better than the recursive feature elimination method, which not only performed worse, but also chose the most predictors. It should be noted that both forward and backward selection had the same AUC. However, the forward selection chose fewer predictors, 28 compared to 34 respectively. Thus, forward selection was chose as the most appropriate variable selection technique. Figure X presents the relationship between each variable selection technique. We see that there was significant agreement between forward and backward selections, with 26 predictors being shared by both. Likewise, there was a total of 12 predictors in common between all four techniques. Table X lists the common predictors between each comparison.

After the data was ran through our pipeline, the final dataset consisted of 28 log transformed predictors. Lastly, 100 bootstrap sampled random forest models were performed on said data. Figure X presents the results compared to the multiple logistic regression models proposed by Mourad et al. We see that the random forest model, using the pipeline processed data, preforms better compared to both models proposed by Mourad et al with an AUC of 0.805. Moreover, the variable importance plot in Figure X reiterates the strong predictive performance of the random forest model by indicating that the DNaseI, insulator, and CTCF genomic features are among the top 3 variables most predictive TAD boundaries. The MLR with LASSO estimation only marginally out performs the regular MLR model with AUCs of 0.750 and 0.747 respectively. Likewise, from Table X we can see that there is more similarity in the ranking of important features between the random forest model and the MLR with LASSO model. However, there is still a large disparity, with 12 variables recognized as important by the random forest that are missing from the MLR with LASSO model. Thus, we conclude that a random forest algorithm applied to a dataset ran through the proposed pipeline performs uniformly better than a multiple logistic regression model, regardless if LASSO estimation is used.


# DISCUSSION
