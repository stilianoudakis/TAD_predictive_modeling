---
title: "Computational Prediction of Boundaries of 3D Genomic Domains in Class Imbalance Settings"
csl: styles.ref/genomebiology.csl
output:
  word_document:
    reference_docx: styles.doc/NIH_grant_style.docx
bibliography: References/references.bib
--- 

Spiro C. Stilianoudakis^1^ (stilianoudasc@mymail.vcu.edu), Mikhail G. Dozmorov^1\*^ (mikhail.dozmorov@vcuhealth.org)

^1^ Dept. of Biostatistics, Virginia Commonwealth University, Richmond, VA, 23298, USA  
^\*^ To whom correspondence should be addressed: Virginia Commonwealth University, Richmond, VA, 23298, 804-827-2055, mikhail.dozmorov@vcuhealth.org

# ABSTRACT

**Background.** Chromosome conformation capture sequencing technologies have shown that the three-dimensional (3D) structure of the genome is folded into distinct compartments, known as topologically associated domains (TADs) - units of coordinated gene expression. The location of TAD boundaries is highly conserved, suggesting the presence of epigenomic marks aiding in TAD formation. The ability to predict which epigenomic features are most associated with the TAD boundaries will allow to better understand the regulatory role of the 3D structure of the genome.

Existing methods for predicting associations between genomic elements tend to ignore key characteristics of the genomic data. Specifically, the number of TAD boundaries is much less than the number of other genomic regions, leading to heavily imbalanced classes. Furthermore, most methods utilize direct overlap as a means to quantify the association, while distance, the measure of spatial relationships, remains unaccounted for. Consequently, distances on a genomic scale vary widely, leaving uncertainty how the heavily right-tailed distribution of distance measures will affect the modelâ€™s performance.

**Methods.** We propose a novel data pre-processing pipeline that addresses those shortcomings. Lasso and Elastic Net were used for feature selection, coupled with five classifier methods. A number of classifier performance metrics were assessed, including the F1 measure and Matthew Correlation Coefficient (MCC), and area under the ROC curve (AUROC).

**Results.** Data preprocessing (log2-transformation and standardization) improves the performance of classification algorithms and allows for the ability to more accurately predict which genomic features are most associated with TAD boundaries. In contrast to overlap-based association measures, the distance between genomic elements was the most predictive measure. The random undersampling strategy addresses the class imbalance problem the most effectively in nearly all settings.

**Conclusions.** Current methods used to model the epigenomic features associated with TAD boundaries are insufficiently robust to handle properties of genomic data. Models applied to unprocessed data can have poor predictive performances. Focusing solely on standard performance assessment metrics, such as AUROC, can mask poor performance of the models; thus, the use of more balanced metrics, such as F1 and MCC, is warranted. Our model results in better performances and more accurate identification of important features associated with the formation of TAD boundaries.

# INTRODUCTION

The advent of various genome-wide sequencing technologies, such as high-throughput conformation capture (notably Hi-C), have revealed how the spatial organization of the human genome may affect several epigenetic functions [@lieberman2009comprehensive]. Analyses have shown that the genome is tightly compacted into distinct compartments.  There exist regions within these compartments that have been shown to be highly conserved and self-interacting, and termed topologically associating domains (TADs) [@dixon2012topological]. Evidence suggests that regulatory elements and genes tend to interact more frequently within the same TAD [@symmons2014functional]. This suggests that the boundaries of TADs may play a role in restricting the function of certain genomic elements such as enhancers, thereby impacting the transcription of genes. Furthermore, changing the 3D structure of the DNA, causing disruptions in these domains, can lead to adverse outcomes and diseases like cancer. Therefore, it has become increasingly important to be able to identify the key molecular drivers of the formation of TAD boundaries in order to further our understanding of the human genome.

The mechanisms underlying the formation of TADs are a complex and active area of research. Recently, it has been discovered that insulator sequences have a primary role in orchestrating the topological arrangements of higher-order chromatin architecture [@phillips2013chromatin]. Insulators are multi-faceted regulatory sequences that moderate a variety of genomic processes including activation, repression, and enhancer blocking. Specifically, the insulator binding protein CTCF has been found to be enriched at the boundary sequences of topologically associating domains in human cells and may therefore act as a mediator of long-range chromatin contacts [@zuin2014cohesin]. Other regulatory elements like particular histone modifications such as H3K36 and H3K27 trimethylation, and transcription factors such as ZNF274 and YY1 have been more frequently observed at TAD boundaries than in other regions [@rao20143d]. These have been found to be associated with more open chromatin which alter the accessibility of genes for transcription. The distinct patterns of different proteins and functional elements point toward the opportunity of using computational approaches in identifying which epigenomic features are most predictive of the development of TAD boundaries, allowing us to better understand what leads to their formation.

Current methods rely on the use of classification algorithms to identify which functional genomic elements are best able to discriminate between regions that include TAD boundaries and those that do not. Most methods differ on the techniques used to identify genomic regions that include TAD boundaries, as well as the models and tools used to evaluate the predictive capability of said models. In doing so, many methods ignore key characteristics of domain data that can impair and bias results. Most notably is the introduction of heavily imbalanced classes. Due to the sparcity of TADs throughout the genome, most defined regions will not contain a TAD boundary. It is commonly agreed upon in the machine learning community that imbalanced datasets adversely impact the performance of the classifiers as the learned model is biased towards the majority class to minimize the overall error rate [@estabrooks2004multiple]. Similarly, careful consideration must also be taken when deciding which performance metric(s) to present when evaluating predictive models, especially in the case of imbalanced data. The popularity surrounding the use of ROC curves is that they do not depend on a threshold. However, when the prevalence of an event is low--that is, a defined genomic region containing a TAD boundary--mean probabilities are biased towards the majority class. Likewise, metrics like accuracy and sensitivity and specificity do not incorporate the entirety of the confusion matrix created when validating predictive models on a test data set. Therefore, each of these metrics are likely to be inflated when evaluating model performance.

A study published by Mourad et al. used multiple logistic regression with LASSO regularization to predict TAD boundaries [@mourad2016computational]. They considered binning the genome at both 50 base and 1kb intervals and flanking TAD boundaries by 1kb and 20kb regions. The outcome Y was determined by whether or not a genomic bin overlapped with a flanked boundary. The feature space was obtained by considering the percent overlap between a bin and coordinates defining ChIP-seq peak data. Models were then evaluated using AUROC. Here, the authors ignored the effect of imbalanced classes as well as the use of potentially biased performance metrics.

In a similar study, Hong et al. used domain data from an hESC cell line to build a linear model and predict which genomic elements were associated with TAD boundaries [@hong2017computational]. They defined boundary segments as genomic regions before and after 150 kilobases of the boundary. To solve the imbalance problem, they randomly sampled from regions outside of the 150kb flank.  For their model, the feature space was determined by the number of counts of ChIP-seq peaks defining functional genomic elements that overlapped with the two segments. Individual models were then performed until the best model which included the concensus CTCF signal feature, followed by 10 additional elements was obtained. Here, however, it is likely that 1 iteration of random under-sampling will yield biased results, depending on how representative the under-sampled data is. Likewise, it is unclear how the performances of other balancing techniques compare (i.e. over-sampling or a combination of both under and over-sampling).

Furthermore, there are other aspects of TAD boundary modelling that current methods have failed to consider. Most notably is the concept of distance. As a feature engineering step, the use of distances (in base pairs) from genomic bins to regions of functional genomic elements has largely been ignored. However, these distance characteristics have the potential to offer a more accurate spatial representation of which genomic features are associated with TAD boundaries. Additionally, model performance is heavily contingent upon the resolution of the contact matrix used to identify the location of TADs throughout the genome. It is often unclear from authors of previous studies what resolution contact matrices were used when retrieving TAD boundaries, and how other resolutions would affect their results. A larger resolution contact matrix will result in the identification of larger-sized TADs, and subsequently, less TAD boundary points. This will contribute to smaller sample sizes and could effect predictive performances.

In this study we have developed an ensemble framework that aims to address and compare a variety of data irregularities and characteristics that are associated with the prediction of TAD boundaries. We evaluated domain data obtained from four different resolution contact matrices for the GM12878 cell line including 10 kb, 25 kb, 50 kb, and 100 kb. For each resolution, we examined the inclusion of three different predictor types as the feature space for downstream modeling. We coupled each predictor type with two separate variable reduction techniques. Lastly, we performed a series of three different re-sampling techniques aimed at creating balanced classes. Random forest classification algorithms were performed to both compare each combination of the above ensemble, and investigate which functional genomic features were most associated with the formation of TAD boundaries.  Model performance was evaluated based on a total of four metrics which included test accuracy, area under the ROC curve (AUC), F1 score, and Matthew's Correlation Coefficient (MCC). 

# METHODS

## DOMAIN DATA

Replicate Hi-C data for the GM12878 cell line were downloaded from GEO GSE63525 (Experiments HIC001 to HIC029) [@rao20143d]. The chromosomal coordinates of topologically associating domains throughout the genome were obtained using the Arrowhead algorithm from the Juicer toolbox provided by the Aiden Laboratory (https://github.com/aidenlab/juicer) [@durand2016juicebox]. [??? how many; !!! the first 29 hic matrices (HIC001 to HIC029); should I provide more detail? ??? TBD, why 29?] contact matrices at 5 kb, 25 kb, 50 kb, and 100 kb resolutions. Identified TAD boundaries were represented by their location on the linear genome (GRCh37/hg19 human genome assembly), including start and end coordinates for chromosomes 1 through 22. The start and end coordinates of all hierarchical TADs were concatenated, sorted, and unique TAD boundary points were obtained. 

## MODEL CONSTRUCTION

To establish the data for modeling, the genome was binned into equally sized intervals defined by the data resolution (Figure 1). For example, for a 10 kb resolution contact matrix, the genome was binned into 10 kb intervals. To accommodate for the uncertainty in exact boundary location, the boundary points were flanked on both sized by regions of size of the resolution of the corresponding contact matrix. For example, for the domain data obtained from a 10 kb resolution contact matrix, each uniquely identified TAD boundary was flanked on either side by 10 kb for a total width around each boundary point of 20 kb. A genomic bin was labeled as having a TAD boundary within it (Y=1) if it overlapped with a particular flanked boundary. Otherwise, the bin was labeled as not containing a boundary (Y=0).

## GENOMIC ANNOTATION DATA

Genomic annotation data (GRCh37/hg19 human genome assembly) were obtained from the UCSC Genome Browser Database [@Tyner:2017aa] (Supplementary Table 1). The annotations consisted of a variety of different chromatin states, histone marks, and DNase I hypersensitive sites.  

### FEATURE ENGINEERING USING GENOMIC ANNOTATIONS

Each genomic annotation is typically represented by a set of regions (their genomic coordinates) annotated as having a functional property or biological annotation. Using these sets of genomic annotations, we created three types of predictors that were used as features to analyze their relationships with TAD boundaries (Figure 2):

1. **Overlap Counts (OC)**: For each genomic bin, the total number of instances where a bin overlapped with genomic annotation regions (features) was calculated. In the case of no overlaps the value is set as 0.
   
2. **Overlap Percent (OP)**: For each genomic bin, the percent overlap between the feature width and the total width of the bin was calculated. We defined the feature width as the number of bases that overlapped with the genomic bin. The percent was then calculated by dividing the feature width by the bin width. If multiple overlaps existed, the feature width was defined as the sum of the total number of bases that overlapped with a particular bin. Note that the bin width remained constant for a given resolution (either 10 kb, 25 kb, 50 kb, or 100 kb). Values for bins with no overlaps were set to be 0.

3. **Distance**: For each genomic bin, the distance (in bases) from the center of the bin to the center of the nearest region of a respective genomic annotation region was calculated.

## ENSEMBLE FRAMEWORK

An ensemble of models was established for the purposes of systematically comparing the performances of different parameters in the framework. Each system in the framework is assumed to be composed of a model constructed from a particular data resolution, with a particular predictor type for the feature space (Figure 3).

The data sets used for modeling were composed of the full set of genomic bins that either overlapped with a flanked TAD boundary or did not. These two classes made up the majority and minority sets. The data was then split into a 7:3 ratio of training to testing sets. Each training and testing set was composed of a similar majority to minority class ratio as the full data set. For each training set, an $l_{1}$ norm penalized regularization (LASSO) was performed [??? what for?]. The $\lambda$ penalization term was tuned over a grid of 10 values on an exponential scale ranging from 0.01 to 10. 

### RE-SAMPLING TECHNIQUES

We then evaluated three re-sampling techniques (in addition to no re-sampling) on the reduced training set, in order to evaluate the problem of imbalanced classes. They are detailed below:

1. **No Sampling**: All of the data points from the majority and minority class of the training set were used.

2. **Random Under-Sampling (RUS)**: All of the minority classes from the training set were used. Sampling without replacement was used to obtain the same number of the majority classes. We performed 50 iterations of random under-sampling. At each iteration a random forest classification algorithm was performed. Performance metrics were aggregated by taking the average across all of the iterations.

3. **Random Over-Sampling (ROS)**: All of the majority classes from the training set were used. Sampling with replacement was used to obtain the same number of the minority classes. Similar to the under-sampling technique, 50 iterations were performed and results were aggregated by taking the average across iterations.

4. **SMOTE** (Synthetic Minority Over-Sampling Technique) [@chawla2002smote]: This method incorporated both random under- and over-sampling. Under-sampling is performed without replacement from the majority class, while over-sampling is performed by creating new synthetic observations using the minority class. To account for the bias introduced by the under-sampling, we performed 50-iterations of SMOTE The user is able to specify the parameters denoting the percent of over- and under-sampling from the two classes. We chose the parameters that would create perfectly balanced classes. The `DMwR` R package (version 3.4.2) was used to perform SMOTE. 

### CLASSIFICATION

A classification algorithm in the form of a random forest was performed and validated using the same test set for all models in the ensemble (Figure 3 F). 10-fold cross validation was used to reduced bias due to random dataset generation. The default number of features to consider at each node of the random forest algorithm was set as the square root of the number of features in the model. Likewise, the number of ensemble trees to aggregate was set at 500. Once the model was implemented, it was assessed using the test set, and performance metrics were then recorded. 

### MODEL EVALUATION & PREDICTION

The efficacy of different ensemble systems was compared using various performance metrics including accuracy, AUC, F1-score, and MCC. These metrics are defined as follows:

$$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$
$$F1 - Score = \frac{2TP}{2TP + FP + FN}$$
$$MCC = \frac{TP \times TN - FP \times FN}{\sqrt{ (TP + FP)(TP+FN)(TN+FP)(TN+FN) }}$$

Here, TP refers to the number of bins correctly identified as containing a TAD boundary (true positives), FP refers to the number of bins incorrectly identified as containing a TAD boundary (false positives), TN refers to the number of bins correctly identified as not containing a TAD boundary (true negatives), and FN refers to the number of bins incorrectly identified as not containing a TAD boundary. Each of these quantities are obtained from the confusion matrix created by validating the model on the testing set.  We also considered the AUC for each model by computing the average trapezoidal approximations for the curve created by the true positive rates (TPR) and false positive rates (FPR).

For the task of identifying the functional genomic elements that were most predictive of the formation of TAD boundaries, we evaluated the variable importances associated with each predictor of the random forest model. For each tree, the prediction accuracy on the out-of-bag portion of the data is recorded. Then the same is done after permuting each predictor variable. The difference between the two accuracies are then averaged over all trees, and normalized by the standard error [@kuhn2012caret]. 

# RESULTS

## ENSEMBLE COMPARISONS

We evaluated and compared Hi-C datasets at four different resolutions R = {10 kb, 25 kb, 50 kb, 100 kb}, used three predictor types P = {OC, OP, Distance}, two variable reduction techniques V = {LASSO, Elastic-Net}, and four class balancing techniques C = {None, RUS, ROS, SMOTE}. Therefore, a system produced from the ensemble framework is defined as: E = {r, p, v, c}, where r $\in$ R, p $\in$ P, v $\in$ V, and c $\in$ C. Letting |X| denote the cardinality of each set, we evaluated |R| x |P| x |V| x |C| different ensemble systems, totaling 96 (=4 $\times$ 3 $\times$ 2 $\times$ 4) separate models. For simplicity, we present the most significant results, with the complete results available as Supplementary Tables.

### CLASS DISTRIBUTIONS ACROSS RESOLUTIONS

The coordinates of the corresponding 10 kb resolution contact maps resulted in a total of 44948 genomic bins [??? To be modified for the whole genome] (Table 2). There were only 3083 (6.9%) bins that overlapped with a flanked TAD boundary [??? What is flanked TAD boundary? Why do we care?]. An increase in resolution resulted in an overall decrease in the number of genomic bins, as well as a slighly less degree of class imbalance. The percentage of imbalance for each of the other resolutions were found to be  14.0%, 13.7%, and 12.2% for 25 kb, 50kb, and 100kb resolutions respectively. [??? Add exact numbers of class imbalance for each resolution; !!! added exact numbers] (Supplementaty Table 2). [??? Do not understand. I understand the ratio of #minority/#majority, but what % tells?; !!!was overally average of class imbalance for the 4 data resolutions; removed sentence; doesn't seem relevant ??? We should rewrite using the ratio of #minority/#majority].  After applying each resampling technique to the training sets for each data resolution, we obtained perfectly balanced classes (Figure 4). That is, the ratio of bins that overlapped with flanked TAD boundaries to bins that did not was 1:1.

### CLASS IMBALANCE HINDERS PERFORMANCE

We first assessed performances on random forest models built on fully unbalanced training sets across each resolution, for each predictor type (Figure 5). When looking at the the conventional metrics used for assessment (accuracy and AUC), models that were not corrected for class imbalance appeared to perform reasonably well.  However, when we considered the F1-score and MCC, we observed a significant degradation in performance across both resolution and predictor type. This was due in part to each models' inability to correctly classify the genomic bins that overlapped with flanked TAD boundaries (true positives, Supplementary Table 3). Even without correcting for the class imbalance, we found that, within predictor types, models with distance type predictors consistently outperformed the other two predictor types across all performance metrics.

### RANDOM UNDER-SAMPLING IMPROVES MODEL PERFORMANCE

When comparing re-sampling techniques it was found that performing 50 iterations of random under-sampling yielded the best performances for both F1-Scores and MCC metrics, across all resolutions and predictor types (Figure 6). Models using 50-iterations of the SMOTE algorithm performed comparitively similar to those using RUS, across all resolutions and predictor types (supplementary Figure 1A). However, it was observed that models using 50-iterations of random over-sampling performed substantially worse than both RUS and SMOTE (Supplementary Figure 1B). More importantly, there was a notable decrease in both accuracy and AUC metrics when performing random under-sampling compared to models with no class balancing. This was evidenced by the more balanced interplay between the componenets of the confusion matrices created when validating the models (Supplementary Table 4). That is, less weight was carried by the true negative cases. This feature was also observed for models using SMOTE and ROS (Supplementary Table 5). As was the case for models with no class-balancing, there was a clear improvement when performing RUS for models with distance-type predictors, across all resolutions.

### DISTANCE TYPE PREDICTORS OUT-PERFORM OTHER PREDICTOR TYPES

[??? Why not using all predictors together? Combine it together with the previous steps, testing no sampling, RUS, and the effect of distance; !!!running on cluster]

In order to more efficiently assess the impact of feature engineering on predictive performance, we directly compared models using each of the three predictor types, across all resolutions, while using 50 iterations of random under-sampling to account for the class imbalance. It was observed that the models built using distance-type features performed substanially better than the other two (Figure 7). This improvement in performance was observed across each of the 4 performance metrics considered. Interestingly, we found that models with overlap percent (OP) type predictors performed worse than those with simple overlap counts (OC), regardless of data resolution. This is notable because, OP predictors can be thought of as a more refined version of OC predictor. Likewise, there have been established methods from previous research that have used OP predictors when attempting to determine which genomic features are most predictive of TAD boundary formation [@mourad2016computational].

### PERFORMANCES DEGRADE AS RESOLUTION INCREASES [??? Terminology: 5kb - high resolution. 100kb - low resolution. Adjust the text]

Finally, we directly compared the performances of models across the different resolutions. The comparisons consisted of random forest models using distance type predictors, elastic-net regularization, and 50 iterations of random under-sampling. The model using 5kb resolution domain data was found to perform slightly better compared to the 25kb and 50kb resolutions (Figure 9). A sharp decrease in performance was seen in the 100kb resolution. [??? This message is already evident from previous paragraphs and results. Not necessary to repeat it]

The differences in performances was most evident when comparing the variable importances across the 4 resolutions. [??? You never said and justified that you use distance predictor.] We found that for the 5kb resolution, the most predictive elements included insulator proteins, DNase hypersensitive sites, the transcription factor CTCF, as well as histone modifications H3k9ac, H2az, and H3k4me2 (Figure 10 A). Although, the insulator protein is featured as a top predictor in 2 of the other 3 resolutions, the rest of the predictors were less consistent among each other and less in agreement with the literature (Figure 10 B-D). The results from Figures 9 and 10 confirm that the model results appear to degrade as resolution increases with respect to both prediction and the identification of genomic elements associated with TAD boundaries.


#Discussion



# Abbreviations



# Acknowledgements

_Conflict of Interest._ None.

# Funding



# Tables

# Figures

# Table Legends

## Table 1: Class Distributions

Summary of the class distributions for the 5 kb resolution domain data, across each re-sampling technique. All re-sampling techniques yielded completely balanced classes. That is, there was a 1:1 relationship between the majority and minority classes after sampling took place.

# Figure legends

## Figure 1: Model Construction

Diagram of the model construction used for downstream analysis. The linear genome was binned according to the resolution of the respective HiC experiment (either 10 kb, 25 kb, 50 kb, or 100 kb intervals). TAD boundaries were then flanked by 1-unit on either side of the boundary point. The unit flanking was indicative of the resolution that the domain data was obtained from (i.e. for 10 kb resolution, 1 unit represents 10 kb for a total flanking region of 20 kb). The response vector Y used for classification was determined by whether or not a genomic bin overlapped with a flanked region. The positional coordinates of each functional genomic element, obtained from ENCODE, were then used to define the feature space of the models.

## Figure 2: Predictor Types 

Diagram of the 3 predictor types considered when assessing the relationship between TAD boundaries and functional genomic elements. Each predictor type was used as the feature space in downstream analyses for predicting which functional genomic elements were associated with the formation of TAD boundaries. Featured above are bin-specific examples of the construction of each predictor type. (Left) The overlap count (OC) predictors were calculated by considering the total number of elemental regions that overlapped with each genomic bin. (Middle) The overlap percent (OP) predictors were calculated by dividing the sum of all feature widths within each specific bin and dividing by the total bin width (either 5, 25, 50, or 100 kilobases given resolution of boundary data). (Right) The distance predictors were calculated by measuring the distance (in base pairs) from the center of each genomic bin to the center of the nearest elemental region of interest. The two green segments directly below the rightmost enlarged figure represent the center of the overlapping regions defining the respective functional genomic element.

## Figure 3: Ensemble Framework/Model Building Pipeline

A diagram of the model building pipeline given a combination of inputs from the ensemble framework. The data was split into a 7:3 training set to testing set ratio, an $l_{1}$ norm regularization (LASSO) was implemented, and a random forest classification algorithm was performed. Each model was then validated on the same testing set. 

## Figure 4: Class Imbalance

Barplots illustrating the class imbalance problem featured across each of the four different resolutions that were analyzed. Minority classes represent the number of genomic bins that contain a TAD boundary, while the majority classes represent the number of genomic bins that do not contain a TAD boundary. 

## Figure 5: Performances of Models with No Class-Balancing

Barplots measuring the predictive performance of models built on imbalanced datasets. The performance metrics considered were accuracy, AUC, F1-Score, and MCC. Performances were compared across 4 resolutions (10 kb, 25kb, 50kb, and 100 kb), for each predictor type (OC, OP, and Distances).

## Figure 6: Performances of Models with Randomly Under-sampled Data.

Barplots measuring the predictive performance of models built on datasets using 50 iterations of random under-sampling. The performance metrics considered were accuracy, AUC, F1-Score, and MCC. Performances were compared across 4 resolutions (10 kb, 25kb, 50kb, and 100 kb), for each predictor type (OC, OP, and Distances).

# Supplementary Tables and Figures


# Supplementary Legends

## Table 1: List of Genomic Annoations. 

The full list of genomic annotations used in downstream analyses. These annotations were the functional genomic elements used to predict the formation of TAD boundaries. They were obtained via ChIP-Seq experiments, mapped to human genome assembly hg19, and made available by the ENCODE Consortium. Each element is denoted by its genomic class, and which cell type it is applied to. The elements that are invariant to a specific cell type are denoted by "Invariant". Additionally, a breif description and specific paths for downloads are also provided.

## Table 2: Class Distributions for Other Resolutions

Summary of the class distributions for each of the other resolution domain data sets (25 kb, 50 kb, and 100 kb), across each re-sampling technique. As with the 5 kb data, all re-sampling techniques yielded completely balanced classes. That is, there was a 1:1 relationship between the majority and minority classes after sampling took place.

## Table 3: Model Performances When Not Accounting for Class Imbalance

Results of various metrics used to assess predictive performances for models that were built on fully imbalanced datasets. 

## Figure 1: Performances of Models with Both SMOTE-Balanced and Randomly Over-sampled Data.

Barplots measuring the predictive performance of models built on datasets using 50 iterations of both the SMOTE algorithm (A) and random over-sampling (B).  The performance metrics considered were accuracy, AUC, F1-Score, and MCC. Performances were compared across 4 resolutions (10 kb, 25kb, 50kb, and 100 kb), for each predictor type (OC, OP, and Distances).

## Table 4:

Results of various metrics used to assess predictive performances for models that were built on random under-sampled datasets. 

## Table 5: 

Results of various metrics used to assess predictive performances for models that were built on both SMOTE-balanced and random over-sampled datasets. 

# References


