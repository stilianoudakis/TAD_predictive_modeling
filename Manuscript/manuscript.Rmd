---
title: "Computational Prediction of Boundaries of 3D Genomic Domains in Class Imbalance Settings"
csl: styles.ref/genomebiology.csl
output:
  word_document:
    reference_docx: styles.doc/NIH_grant_style.docx
bibliography: References/references.bib
--- 

Spiro C. Stilianoudakis^1^ (stilianoudasc@mymail.vcu.edu), Mikhail G. Dozmorov^1\*^ (mikhail.dozmorov@vcuhealth.org)

^1^ Dept. of Biostatistics, Virginia Commonwealth University, Richmond, VA, 23298, USA  
^\*^ To whom correspondence should be addressed: Virginia Commonwealth University, Richmond, VA, 23298, 804-827-2055, mikhail.dozmorov@vcuhealth.org

# ABSTRACT

**Background.** Chromosome conformation capture sequencing technologies have shown that the three-dimensional (3D) structure of the genome is folded into distinct compartments, known as topologically associated domains (TADs) - units of coordinated gene expression. The location of TAD boundaries is highly conserved, suggesting the presence of epigenomic marks aiding in TAD formation. The ability to predict which epigenomic features are most associated with the TAD boundaries will allow to better understand the regulatory role of the 3D structure of the genome.

Existing methods for predicting associations between genomic elements tend to ignore key characteristics of the genomic data. Specifically, the number of TAD boundaries is much less than the number of other genomic regions, leading to heavily imbalanced classes. Furthermore, most methods utilize direct overlap as a means to quantify the association, while distance, the measure of spatial relationships, remains unaccounted for. Consequently, distances on a genomic scale vary widely, leaving uncertainty how the heavily right-tailed distribution of distance measures will affect the modelâ€™s performance.

**Methods.** We propose a novel data pre-processing pipeline that addresses those shortcomings. Lasso and Elastic Net were used for feature selection, coupled with five classifier methods. A number of classifier performance metrics were assessed, including the F1 measure and Matthew Correlation Coefficient (MCC), and area under the ROC curve (AUROC).

**Results.** Data preprocessing (log2-transformation and standardization) improves the performance of classification algorithms and allows for the ability to more accurately predict which genomic features are most associated with TAD boundaries. In contrast to overlap-based association measures, the distance between genomic elements was the most predictive measure. The random undersampling strategy addresses the class imbalance problem the most effectively in nearly all settings.

**Conclusions.** Current methods used to model the epigenomic features associated with TAD boundaries are insufficiently robust to handle properties of genomic data. Models applied to unprocessed data can have poor predictive performances. Focusing solely on standard performance assessment metrics, such as AUROC, can mask poor performance of the models; thus, the use of more balanced metrics, such as F1 and MCC, is warranted. Our model results in better performances and more accurate identification of important features associated with the formation of TAD boundaries.

# INTRODUCTION

The advent of various genome-wide sequencing technologies, such as high-throughput conformation capture (notably Hi-C), have revealed how the spatial organization of the human genome may affect several epigenetic functions [@lieberman2009comprehensive]. Analyses have shown that the genome is tightly compacted into distinct compartments.  There exist regions within these compartments that have been shown to be highly conserved and self-interacting, and termed topologically associating domains (TADs) [@dixon2012topological]. Evidence suggests that regulatory elements and genes tend to interact more frequently within the same TAD [@symmons2014functional]. This suggests that the boundaries of TADs may play a role in restricting the function of certain genomic elements such as enhancers, thereby impacting the transcription of genes. Furthermore, changing the 3D structure of the DNA, causing disruptions in these domains, can lead to adverse outcomes and diseases like cancer. Therefore, it has become increasingly important to be able to identify the key molecular drivers of the formation of TAD boundaries in order to further our understanding of the human genome.

The mechanisms underlying the formation of TADs are a complex and active area of research. Recently, it has been discovered that insulator sequences have a primary role in orchestrating the topological arrangements of higher-order chromatin architecture [@phillips2013chromatin]. Insulators are multi-faceted regulatory sequences that moderate a variety of genomic processes including activation, repression, and enhancer blocking. Specifically, the insulator binding protein CTCF has been found to be enriched at the boundary sequences of topologically associating domains in human cells and may therefore act as a mediator of long-range chromatin contacts [@zuin2014cohesin]. Other regulatory elements like particular histone modifications such as H3K36 and H3K27 trimethylation, and transcription factors such as ZNF274 and YY1 have been more frequently observed at TAD boundaries than in other regions [@rao20143d]. These have been found to be associated with more open chromatin which alter the accessibility of genes for transcription. The distinct patterns of different proteins and functional elements point toward the opportunity of using computational approaches in identifying which epigenomic features are most predictive of the development of TAD boundaries, allowing us to better understand what leads to their formation.

Current methods rely on the use of classification algorithms to identify which functional genomic elements are best able to discriminate between regions that include TAD boundaries and those that do not [@mourad2016computational; @hong2017computational; @huang2015predicting]. Most methods differ on the techniques used to identify genomic regions that include TAD boundaries, as well as the models and tools used to evaluate the predictive capability of said models. Moreover, many methods ignore key characteristics of domain data that can impair and bias results. 

Most notably is the introduction of heavily imbalanced classes. Due to the sparcity of TADs throughout the genome, most defined regions will not contain a TAD boundary. In a classification setting, when one is attempting to discriminate between regions with and without TAD boundaries, this will contribute to small imbalance ratios (defined as the ratio of minority to majority classes) [@Orriols-Puig2008]. It is commonly agreed upon in the machine learning community that imbalanced datasets adversely impact the performance of the classifiers as the learned model is biased towards the majority class to minimize the overall error rate [@lusa2010class;@chen2013influence]. Similarly, careful consideration must also be taken when deciding which performance metric(s) to present when evaluating predictive models, especially in the case of imbalanced data. 

Commonly used measures of model performance for binary classifiers include the area under the receiver operating curve (AUROC). The popularity surrounding the use of ROC curves is that they do not depend on a threshold. However, when the prevalence of an event is low--that is, a defined genomic region containing a TAD boundary--mean probabilities are biased towards the majority class. This results in the area of interest under an ROC curve to be compressed toward a small corner in the ROC space [@prati2011survey]. While not directly affecting the value of the AUROC, this can have severe consequences on the interpretability of the model's performance. A better threshold-free measure to use when dealing with imbalanced data in the area under the precision-recall curve (AUPRC). It has been shown that the use of AUPRC with imbalanced datasets yields more accurate and intuitive interpretation of model performance when compared to AUROC [@saito2015precision]. Likewise, metrics like accuracy and specificity are also problematic when evaluating model performance on imbalance data. In each case, the weight of the measure is carried primarily by the correct classification of the majority class. Better measures to consider are the F1-Score and Matthew's Correlation Coefficient (MCC) [@jeni2013facing]. The F1-Score can be interpreted as a weighted average of the precision and recall values, while MCC is, in essence, the correlation coefficient between the observed and predicted binary classifications. In either case, all 4 quadrants of the confusion matrix are used, making for more balanced measures in the case of imbalanced data [@chicco2017ten].

In addition to employing suitable metrics for evaluating models validated on imbalanced data, there also exist several external or data level solutions. These mostly constitute as resampling techniques, in which random sampling is used to either replicate or removed data points in order to create a more balanced dataset. Many such solutions have been developed in a variety of fields related to machine learning [@estabrooks2004multiple; @chawla2003smoteboost; @chen2004using; @khoshgoftaar2007empirical]. Likewise, it has been shown that quite simple resampling techniques can drastically improve model performance in the face of imbalanced data [@japkowicz2002class; @dubey2014analysis,]. 

Furthermore, there are other aspects of TAD boundary modelling that current methods have failed to consider. Most notably is the concept of distance. As a feature engineering step, the use of distances (in base pairs) from genomic bins to regions of functional genomic elements has largely been ignored. However, these distance characteristics have the potential to offer a more accurate spatial representation of which genomic features are associated with TAD boundaries. Additionally, model performance is heavily contingent upon the resolution of the contact matrix used to identify the location of TADs throughout the genome. It is often unclear from authors of previous studies what resolution contact matrices were used when retrieving TAD boundaries, and how other resolutions would affect their results. A larger resolution contact matrix will result in the identification of larger-sized TADs, and subsequently, less TAD boundary points. This will contribute to smaller sample sizes and could effect predictive performances.

In this study we have developed an ensemble framework that aims to address and compare a variety of data irregularities and characteristics that are associated with the prediction of TAD boundaries including class imbalance, feature engineering, and contact map resolution. We evaluated domain data obtained from four different resolution contact matrices for the GM12878 cell line including 10 kb, 25 kb, 50 kb, and 100 kb. For each resolution, we examined the inclusion of 3 different predictor types as the feature space for downstream modeling. We then performed a series of 4 different re-sampling techniques aimed at creating balanced classes. Random forest classification algorithms were performed to both compare each combination of the above ensemble, and investigate which functional genomic features were most associated with the formation of TAD boundaries.  Model performance was evaluated based on a total of four metrics which included test accuracy, area under the precision-recall curve (AUPRC), F1 score, and Matthew's Correlation Coefficient (MCC). This process was then repeated for X additional cell lines including K562, ......

# METHODS

## DOMAIN DATA

Replicate Hi-C data for the GM12878 cell line were downloaded from GEO GSE63525 (Experiments HIC001 to HIC018; produced using the MbolI restriction enzyme) [@rao20143d]. The chromosomal coordinates of topologically associating domains throughout the genome were obtained using the Arrowhead algorithm from the Juicer toolbox provided by the Aiden Laboratory (https://github.com/aidenlab/juicer) [@durand2016juicebox]. Domain data was extracted at 4 different kilobase (kb) resolutions including 10 kb, 25 kb, 50 kb, and 100 kb. Identified TAD boundaries were represented by their location on the linear genome (GRCh37/hg19 human genome assembly), including start and end coordinates for chromosomes 1 through 22. The start and end coordinates of all hierarchical TADs were concatenated, sorted, and unique TAD boundary points were obtained. 

## MODEL CONSTRUCTION

To establish the data for modeling, the genome was binned into equally sized intervals defined by the data resolution (Figure 1). For example, fordomain data obtained from a 10 kb resolution contact matrix, the genome was binned into 10 kb intervals. To accommodate for the uncertainty in exact boundary location, the boundary points were flanked on both sides by the size of the resolution of the corresponding contact matrix. For example, returning to the 10 kb resolution example, each uniquely identified TAD boundary was flanked on either side by 10 kilobases for a total width around each boundary point of 20 kb. A genomic bin was labeled as having a TAD boundary within it (Y=1) if it overlapped with a particular flanked boundary. Otherwise, the bin was labeled as not containing a boundary (Y=0).

## GENOMIC ANNOTATION DATA

Genomic annotation data (GRCh37/hg19 human genome assembly) were obtained from the UCSC Genome Browser Database [@Tyner:2017aa] (Supplementary Table 1). The annotations consisted of a variety of different chromatin states, histone marks, and transcription factor binding sites using ChIP-seq peak experiments. Each genomic annotation was represented by a set of regions (their genomic coordinates) annotated as having a functional property or biological significance.

## ENSEMBLE FRAMEWORK

An ensemble of models was established for the purposes of systematically comparing the performances of different parameters in the framework. Each system in the framework is assumed to be composed of a model constructed from a particular data resolution, with a particular predictor type for the feature space (Figure 2).

The data sets used for modeling were composed of the full set of genomic bins that either overlapped with a flanked TAD boundary or did not. These two classes made up the minority and majority sets respectively. The data was then split into a 7:3 ratio of training to testing sets. Each training and testing set was composed of a similar majority to minority class ratio as the full data set. That is, for the task of prediction, the test set remained constant for all ensemble systems in order to account for a fair and unbiased comparison.

### FEATURE ENGINEERING AND REDUCTION USING GENOMIC ANNOTATIONS

Using the sets of genomic annotations, we created three types of predictors that were used as features to analyze their relationships with TAD boundaries (Figure 3):

1. **Overlap Counts (OC)**: For each genomic bin, the total number of instances where a bin overlapped with genomic annotation regions (features) was calculated. In the case of no overlaps the value is set as 0.
   
2. **Overlap Percent (OP)**: For each genomic bin, the percent overlap between the feature width and the total width of the bin was calculated. We defined the feature width as the number of bases that overlapped with the genomic bin. The percent was then calculated by dividing the feature width by the bin width. If multiple overlaps existed, the feature width was defined as the sum of the total number of bases that overlapped with a particular bin. Note that the bin width remained constant for a given resolution (either 10 kb, 25 kb, 50 kb, or 100 kb). Values for bins with no overlaps were set to be 0.

3. **Log Distance**: For each genomic bin, the log of the distance (in bases) from the center of the bin to the center of the nearest region of a respective genomic annotation region was calculated. The log transformation was used as a normalization technique in order to account for the skewness of the data (Supplementary Figure 1)

To assess the predictive performance for each predictor type, we performed individual random forest classification algorithms utilizing each set predictor types as the feature space, in addition to a model with all combined types. Precision-Recall (PR) Curves, and subsequent area under the PR curves (AUPRC), were used to evaluate which predictor type contributed to the best model performance. Recursive feature elimination (RFE) was then used to determine the optimal number of features for models within each set of predictor types. Here, random forest models were used to assign weights to a set features of a given size. The optimal number of features was determined by the AUPRC of the corresponding model.

### RE-SAMPLING TECHNIQUES

We then evaluated three re-sampling techniques (in addition to no re-sampling) on the reduced training set, in order to evaluate the problem of imbalanced classes. They are detailed below:

1. **No Sampling**: All of the data points from the majority and minority class of the training set were used.

2. **Random Under-Sampling (RUS)**: All of the minority classes from the training set were used. Sampling without replacement was used to obtain the same number of the majority classes. We performed 50 iterations of random under-sampling. At each iteration a random forest classification algorithm was performed. Performance metrics were aggregated by taking the average across all of the iterations.

3. **Random Over-Sampling (ROS)**: All of the majority classes from the training set were used. Sampling with replacement was used to obtain the same number of the minority classes. Similar to the under-sampling technique, 50 iterations were performed and results were aggregated by taking the average across iterations.

4. **SMOTE** (Synthetic Minority Over-Sampling Technique): This method incorporates both random under- and over-sampling. Under-sampling is performed without replacement from the majority class, while over-sampling is performed by creating new synthetic observations using the minority class [@chawla2002smote]. To account for the bias introduced by the under-sampling, we performed 50-iterations of SMOTE The user is able to specify the parameters denoting the percent of over- and under-sampling from the two classes. We chose the parameters that would create perfectly balanced classes. The `DMwR` package in R (version 3.4.2) was used to perform SMOTE. 

5. **ROSE** (Random Over-Sampling Examples): Similar to SMOTE, ROSE combines combines techniques of over-sampling and under-sampling. However, contrary to SMOTE, all of the data generated by ROSE is synthetic. The data is created by sampling from one of the two classes, then generating a new example in its neighborhood using a smoothed bootstrap approach. The shape of the neighborhood is determined by the kernal density estimate of the two classes [@lunardon2013r]. Another important distinction between ROSE and SMOTE is that, for ROSE, the creation of perfectly balanced classes is unlikely due to the randomness in sampling between the two classes. The `ROSE` package in R (version 3.4.2) was used to perform ROSE.

### CLASSIFICATION

A classification algorithm in the form of a random forest was performed and validated using the same test set for all models in the ensemble. To reduce bias due to random dataset generation, 10-fold cross validation was used. The default number of features to consider at each node of the random forest algorithm was set as the square root of the number of features in the model. Likewise, the number of ensemble trees to aggregate was set at 500. Once the model was implemented, it was assessed using the test set, and performance metrics were then recorded. 

### MODEL EVALUATION & PREDICTION

The efficacy of different ensemble systems was compared using various performance metrics including accuracy, AUC, F1-score, and MCC. These metrics are defined as follows:

$$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$
$$F1 - Score = \frac{2TP}{2TP + FP + FN}$$
$$MCC = \frac{TP \times TN - FP \times FN}{\sqrt{ (TP + FP)(TP+FN)(TN+FP)(TN+FN) }}$$

Here, TP refers to the number of bins correctly identified as containing a TAD boundary (true positives), FP refers to the number of bins incorrectly identified as containing a TAD boundary (false positives), TN refers to the number of bins correctly identified as not containing a TAD boundary (true negatives), and FN refers to the number of bins incorrectly identified as not containing a TAD boundary. Each of these quantities are obtained from the confusion matrix created by validating the model on the testing set. The evaluation metrics listed above are all considered single threshold measures. That is, they are defined for individual thresholds that separated class prediction. Thererfore they are unable to give an overview of the potential range of performance as thresholds vary. A full list of the single threshold measures used (including additional metrics not reported), along with their respective formulas, are provided in Supplementary Table 6. In order to evaluate the trade-off between precision and recall, we also considered a threshold free measure in form of the area under the precision recall curve (AUPRC).

For the task of identifying the functional genomic elements that were most predictive of the formation of TAD boundaries, we evaluated the variable importances associated with each predictor of the random forest model. For each tree, the prediction accuracy on the out-of-bag portion of the data is recorded. Then the same was done after permuting each predictor variable. The difference between the two accuracies were then averaged over all trees, and normalized by the standard error [@kuhn2012caret]. 

# RESULTS

## ENSEMBLE COMPARISONS

We evaluated and compared Hi-C datasets at four different resolutions R = {10 kb, 25 kb, 50 kb, 100 kb}, used three predictor types P = {OC, OP, Distance}, two variable reduction techniques V = {LASSO, Elastic-Net}, and five class balancing techniques C = {None, RUS, ROS, SMOTE, ROSE}. A system produced from the ensemble framework was defined as: E = {r, p, v, c}, where r $\in$ R, p $\in$ P, v $\in$ V, and c $\in$ C. Letting |X| denote the cardinality of each set, we evaluated |R| x |P| x |V| x |C| different ensemble systems, totaling 120 (=4 $\times$ 3 $\times$ 2 $\times$ 5) separate models. For simplicity, we present the most significant results, with the complete results available as Supplementary Tables.

### CLASS DISTRIBUTIONS ACROSS RESOLUTIONS

The coordinates of the corresponding 10 kb resolution contact maps resulted in a total of X genomic bins [??? To be modified for the whole genome]. There were only Y bins that overlapped with a flanked TAD boundary representing the minority class, for an imbalance ratio of (X-Y):Y [??? To be modified for the whole genome]. After applying each resampling technique to the training set, we obtained perfectly balanced classes for all except the ROSE technique (Figure 4). 

An increase in resolution resulted in an overall decrease in the number of genomic bins, as well as a slight decrease in the imbalance ratio (Supplementary Figure 2). After performing the resampling techniques, the resulting imbalance ratios remained similar across the other 3 data resolutions (Supplementary Figure 2).

### DISTANCE-TYPE PREDICTORS PERFORM BEST



#Discussion



# Abbreviations



# Acknowledgements

_Conflict of Interest._ None.

# Funding



# Tables

# Figures

# Table Legends

## Table 1: Class Distributions

Summary of the class distributions for the 5 kb resolution domain data, across each re-sampling technique. All re-sampling techniques yielded completely balanced classes. That is, there was a 1:1 relationship between the majority and minority classes after sampling took place.

# Figure legends

## Figure 1: Model Construction

Diagram of the model construction used for downstream analysis. The linear genome was binned according to the resolution of the respective HiC experiment (either 10 kb, 25 kb, 50 kb, or 100 kb intervals). TAD boundaries were then flanked by 1-unit on either side of the boundary point. The unit flanking was indicative of the resolution that the domain data was obtained from (i.e. for 10 kb resolution, 1 unit represents 10 kb for a total flanking region of 20 kb). The response vector Y used for classification was determined by whether or not a genomic bin overlapped with a flanked region. The positional coordinates of each functional genomic element, obtained from ENCODE, were then used to define the feature space of the models.

## Figure 2: Ensemble Framework/Model Building Pipeline

A diagram of the model building pipeline given a combination of inputs from the ensemble framework. The data was split into a 7:3 training set to testing set ratio, an $l_{1}$ norm regularization (LASSO) was implemented, and a random forest classification algorithm was performed. Each model was then validated on the same testing set. 

## Figure 3: Predictor Types 

Diagram of the 3 predictor types considered when assessing the relationship between TAD boundaries and functional genomic elements. Each predictor type was used as the feature space in downstream analyses for predicting which functional genomic elements were associated with the formation of TAD boundaries. Featured above are bin-specific examples of the construction of each predictor type. (Left) The overlap count (OC) predictors were calculated by considering the total number of elemental regions that overlapped with each genomic bin. (Middle) The overlap percent (OP) predictors were calculated by dividing the sum of all feature widths within each specific bin and dividing by the total bin width (either 5, 25, 50, or 100 kilobases given resolution of boundary data). (Right) The distance predictors were calculated by measuring the distance (in base pairs) from the center of each genomic bin to the center of the nearest elemental region of interest. The two green segments directly below the rightmost enlarged figure represent the center of the overlapping regions defining the respective functional genomic element.

## Figure 4: Class Imbalance

Barplots illustrating the class imbalance problem featured across each of the four different resolutions that were analyzed. Minority classes represent the number of genomic bins that contain a TAD boundary, while the majority classes represent the number of genomic bins that do not contain a TAD boundary. 

## Figure 5: Performances of Models with No Class-Balancing

Barplots measuring the predictive performance of models built on imbalanced datasets. The performance metrics considered were accuracy, AUC, F1-Score, and MCC. Performances were compared across 4 resolutions (10 kb, 25kb, 50kb, and 100 kb), for each predictor type (OC, OP, and Distances).

## Figure 6: Performances of Models with Randomly Under-sampled Data.

Barplots measuring the predictive performance of models built on datasets using 50 iterations of random under-sampling. The performance metrics considered were accuracy, AUC, F1-Score, and MCC. Performances were compared across 4 resolutions (10 kb, 25kb, 50kb, and 100 kb), for each predictor type (OC, OP, and Distances).

# Supplementary Tables and Figures


# Supplementary Legends

## Table 1: List of Genomic Annoations. 

The full list of genomic annotations used in downstream analyses. These annotations were the functional genomic elements used to predict the formation of TAD boundaries. They were obtained via ChIP-Seq experiments, mapped to human genome assembly hg19, and made available by the ENCODE Consortium. Each element is denoted by its genomic class, and which cell type it is applied to. The elements that are invariant to a specific cell type are denoted by "Invariant". Additionally, a breif description and specific paths for downloads are also provided.

## Table 2: Class Distributions for Other Resolutions

Summary of the class distributions for each of the other resolution domain data sets (25 kb, 50 kb, and 100 kb), across each re-sampling technique. As with the 5 kb data, all re-sampling techniques yielded completely balanced classes. That is, there was a 1:1 relationship between the majority and minority classes after sampling took place.

## Table 3: Model Performances When Not Accounting for Class Imbalance

Results of various metrics used to assess predictive performances for models that were built on fully imbalanced datasets. 

## Figure 1: Performances of Models with Both SMOTE-Balanced and Randomly Over-sampled Data.

Barplots measuring the predictive performance of models built on datasets using 50 iterations of both the SMOTE algorithm (A) and random over-sampling (B).  The performance metrics considered were accuracy, AUC, F1-Score, and MCC. Performances were compared across 4 resolutions (10 kb, 25kb, 50kb, and 100 kb), for each predictor type (OC, OP, and Distances).

## Table 4:

Results of various metrics used to assess predictive performances for models that were built on random under-sampled datasets. 

## Table 5: 

Results of various metrics used to assess predictive performances for models that were built on both SMOTE-balanced and random over-sampled datasets. 

# References


