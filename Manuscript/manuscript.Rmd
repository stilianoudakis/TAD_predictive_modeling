---
title: "Predictive modeling using genomic annotations"
subtitle: "Pitfalls and Recommendations"
author: "Spiro Stilianoudakis"
date: "August 9, 2018"
header-includes:
    - \usepackage{setspace}\doublespacing
    - \usepackage{amsmath}
output: 
  word_document:
    fig_caption: yes
    fig_height: 3
    fig_width: 2
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ABSTRACT

###Background 
Chromosome conformation capture sequencing technologies have shown that the three-dimensional (3D) structure of the genome is folded into distinct compartments, known as topologically associated domains (TADs) - units of coordinated gene expression. The location of TAD boundaries is highly conserved, suggesting the presence of epigenomic marks aiding in TAD formation. The ability to predict which epigenomic features are most associated with the TAD boundaries will allow to better understand the regulatory role of the 3D structure of the genome.

Existing methods for predicting associations between genomic elements ignore key characteristics of the data. Specifically, the number of TAD boundaries is much less than the number of other genomic regions, leading to heavily imbalanced classes. Furthermore, most methods utilize direct overlap as a means to quantify the association, while distance, the measure of spatial relationships, remains unaccounted for. Consequently, distances on a genomic scale vary widely, leaving uncertainty how the heavily right-tailed distribution of distance measures will affect the modelâ€™s performance.


###Methods 
We propose a novel data pre-processing pipeline that addresses those shortcomings. A number of classifier performance metrics were assessed, including the F1 measure and Matthew Correlation Coefficient (MCC), and area under the ROC curve (AUROC).

###Results 
Data preprocessing (log2-transformation and standardization) improves the performance of classification algorithms and allows for the ability to more accurately predict which genomic features are most associated with TAD boundaries. 

###Conclusions 
Current methods used to model the epigenomic features associated with TAD boundaries are not robust to handle properties of genomic data. Models applied to unprocessed data can have poor predictive performances. Focusing solely on typical performance assessment metrics, such as AUROC, can mask poor performance of the models; thus, the use of more balanced metrics, such as F1 and MCC, is warranted. Our model results in better performances and more accurate identification of important features associated with the formation of TAD boundaries.

# INTRODUCTION

The advent of various genome-wide sequencing technologies, such as high-throughput conformation capture (notably Hi-C), have revealed how the spatial organization of the human genome may affect several epigenetic functions (Aiden et al.). Analyses have shown that the genome is tightly compacted into distinct compartments.  There exist regions within these compartments that have been shown to be highly conserved and self-interacting, and termed topologically associating domains (TADs) (Dixon et al.). Evidence suggests that regulatory elements and genes tend to interact more frequently within the same TAD (Symmons et al.). This suggests that the boundaries of TADs may play a role in restricting the function of elements such as enhancers, thereby impacting the transcription of genes. Furthermore, changing the 3D structure of the DNA and distrupting these domains can lead to adverse outcomes and diseases like cancer. Therefore it is important to be able to identify the key molecular drivers of the formation of TADs in order to further our understanding of the human genome.

The mechanisms underlying the formation of TADs are a complex and active area of research. Recently, it has been discovered that insulator sequences have a primary role in orchestrating the topological arrangement of higher-order chromatin architecture (Phillips-Cremins et al). Insulators are multi-faceted regulatory sequences that moderate a variety of genomic processes including activation, repression, and enhancer blocking. Specifically, the insulator binding protein CTCF has been found to be enriched at the boundary sequences of topologically associating domains in human cells and may therefore act as a mediator of long range chromatin contacts (Zuin et al.). Other regulatory elements like DNase I hypersensitive sites, the H3K36 trimethylation, and transcription factors such as ZNF274 and YY1 have been more frequently observed at TAD boundaries than in other regions (Hong et al). These have been found to be associated with more open chromatin which alter the accessibility of genes for transcription. The distinct patterns of some of these different proteins and functional elements point toward the opportunity of computational approaches in predicting which epigenomic features are most predictive of the development of TAD boundaries. This will allow us to better understand what leads to their formation. 

Due to the size of Hi-C data and the abundance of available genomic features, few methods have been developed to study the role and interplay of different sets of these features on the folding of DNA. Furthermore, many accepted methods ignore key characteristics of the data that, when addressed, may improve predictive performances. One such pitfall is the issue of highly imbalanced classes. The commonality between most accepted methods for predicting TAD boundaries considers performing a classification algorithm by binning the genome and labeling the bins as either containing a TAD boundary or not. However, due to the sparcity of TADs throughout the genome, most bins will not contain a TAD boundary. This will contribute to highly imbalanced classes and has the potential to introduce predictors with near-zero variance. It has been shown that imbalanced classes can result in poor predictive performances of classification algorithms (Blagus et al).  Furthermore, the inclusion of predictors with near-zero variance can add unnecessary noise to the model and decrease computational efficiency of predictive algorithms. Another problem lies in identifying which positional characteristics of the genomic features will optimize prediction. The use of distances (in base pairs) from genomic bins to regions of functional elements has largely been ignored. However, these distance characteristics offer a more accurate spatial representation of which genomic features are associated with TAD boundaries. Lastly, given that some features tend to colocalize near TAD boundaries, most predictive models may be unable to identify the complete set of features most associated with boundary formation. This can lead to less informative results and restrict our knowledge of how these genomic elements correlate with eachother.

In a previous study (Mourad et al) both a multiple logistic regression model and a LASSO regularized regression model were applied to a wide array of architectural proteins from the GM12878 cell line to predict TAD boundaries. The set of features consisted of whether or not the coordinates of a functional element overlaped with a particular genomic bin (yes or no). In the case of a partial overlap, a percentage of overlap was used. However, the class imbalance issue was not addressed and neither model used is suited to handle multiple correlated predictors. Likewise, it is unclear how the team handled the situation when multiple regions defined by the same genomic element are located within the same bin. The length of the genomic bins can be flexible and as the size increases, there is a greater chance for the occurance of multple regions to be located within the same bin. If a simple indicator (1 or 0) is used, instead of, say, the sum total of regions within that bin, it is possible that a significant amount of information is lost.  Additionally, the team used ROC curves and AUCs to evaluate model performance, which is problematic, especially for highly imbalaned classes (Hanczar et al). A better indicator of predictive performance with classification algorithms is to consider the F1 score and Matthew's Correlation Coefficient (MCC) as they involve all quadrants of a confusion matrix. 

In this study we have developed a novel data pre-processing pipeline that addresses the irregularities in the TAD boundary data provided by contact matrices for the GM12878 cell line. We then performed a variety of machine learning algorithms on the pre-processed data to identify the genomic elements that were most predictive of TAD boundaries. Firstly, we found that the models performed on balanced data out performed those on unbalanced data. Secondly, it was determined that multiple iterations of random under-sampling was the balancing technique that yielded the best results. Thirdly, the inclusion of distances as predictors was found to improve model performance compared to a model with simple overlap predictors. Lastly, it was found that performing an inverse normal transformation of the distance predictors further improved model performance. 

After applying (insert final model(s)) we were able to confirm that cis-regulatory elements like insulators and promotors were highly predictive of TAD boundaries. The specific transcriptional repressor, CCCTC-binding factor (CTCF), was also found to be highly associated with TAD boundaries. Other non-transcription factor sites like DNase I hypersensitive sites and certain histone modifications like H3K36me3 were also found to be better predictors of TAD boundaries.  Our findings confirm that models with pre-processed data and distance-related genomic features not only perform better, but are also able to correctly identify a range of different functional genomic elements associated with the formation of TAD boundaries. This knowlege will allow us to gain better insight into the role that the spatial organisation of the human genome has on gene regulation. 

 

# METHODS



## DOMAIN DATA

Publicly available topologically associating domain data was obtained from GEO with accession GSE53525 for the GM12878 cell line (Rao et. al).  The domain data was constructed from in situ Hi-C contact matrices at a 5kb resolution. Identified TAD boundaries were represented by their location in the genome (hg19 human genome assembly), including chromosome, start and end coordinates. The start and end coordinates were concatenated, sorted, and unique coordinates representing the borders demarcating TADs were obtained. 

The establishment of the data for modeling first consisted of binning the genome into equal sized intervals. This was performed at the same resolution as the respective cell line. That is, 5 kb genomic bins were used. Next, the boundary coordinates were flanked on either side by 5 kb. A genomic bin was labeled as having a TAD boundary within it (Y=1) if it overlapped with a particular flanked boundary. Otherwise, the bin was labeled as not containing a boundary (Y=0). An illustration of the data is presented in Figure X.

## GENOMIC ANNOTATIONS

Annotation data, in the form of functional genomic coordinates, from ChIP-seq experiments was obtained from the Encyclopedia of DNA Elements (ENCODE) Consortium. Similar to Mourad et al. we considered overlaps between bins and regions defined by functional genomic elements when creating the predictor space of our models. If a elemental region was located completely within a bin then the predictor ($X_{i}$) was labeled as 1. If a bin did not overlap with any region then it was labeled as 0. In the case of partial overlaps, a fraction denoting the percent overlap from region to bin was used. However, in contrast to Mourad et al., in the event of multiple regions within the same bin, the sum total of fractions or instances of regions was used as in Figure X.

## DATA PIPELINE

We developed a pipeline that systematically evaluates the problems associated with TAD boundary data in a predictive modeling setting (Figure X). The pipeline addresses X key questions in aiming to improve predictive performances and accurately identify which functional genomic elements are most predictive of TAD boundaries. Prior to initiating the pipeline, predictors with near-zero variances were removed. To identify said predictors, the nearZeroVar function in the CARET package was used. The function considers two metrics. First, the ratio of the most frequent value over the second most frequent value was calculated. Ideally, this ratio would be close to one for well-behaved predictors. Next, the number of unique values divided by the total number of samples multiplied by 100 was calculated. Here, if the frequency ratio was greater than 20 and the percentage of unique values was less than 10, the predictor was flagged as having near-zero variance and removed. 

### Question 1: How severely unbalanced were the classes and what was the affect on model performance?

When binning the genome, the sparcity of TAD boundaries contributed to heavily imbalanced classes. That is, proportionally, only a small number of genomic bins overlapped with a flanked TAD boundary. To assess this issue two multiple logistic regression models were performed. One with unbalanced classes and one with balanced classes created by random under-sampling from the majority class. It was found that the model with balanced classes out-performed the model with unbalanced classes. However, given the vast disparity between classes simply performing one iteration of random under-sampling was not sufficient in determining the best possible balancing technique. 

### Question 2: Which balancing technique performs best?

Three methods were used to evaluate class balance. The first consisted of performing X iterations of over-sampling from the minority class to match the majority class. At each iteration, a multiple logistic regression model was used and performance metrics were recorded. At the end of the X iterations, the performance metrics were aggregated by taking the average. The second method consisted of random under-sampling. Similar to over-sampling, the majority class was randomly under-sampled over X iterations to create balanced classes. Again, at each step a multiple logistic regression model was performed and the results were aggregated using the average.  The last method incorporated the SMOTE command from the DmWR package in R. SMOTE stands for Synthetic Minority Over-sampling Technique. The SMOTE algorithm incorporates both under-sampling (percent under) of the majority class and over-sampling (percent over) of the minority class. The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the k minority class nearest neighbors (here, k=5). Then, the majority class is under sampled by taking a random sample that matches some pre-specified percentage of the updated minority class. A total of four different combinations of percent over and under-sampling were used which included: 100/200, 200/200, 300/200, and 400/200. It is important to note that using a combination of 100/200 (percent over/percent under-sample) will always result in perfectly balanced classes. The other combinations created unbalanced classes with the negative class as the majority to reflect the proportionality of the classes from the original data. Multiple logistic regression models were used and performance metrics were assessed and compared with each of the other techniques. It was determined that the model with data untilizing random under-sampling out-performed all other other balancing techniques. However, to this point we only considered overlaps between genomic bins and the regions that defined functional genomic elements. 

### Question 3: What affect does the inclusion of distances from bin to region have on model performance?

To this point we had only considered overlaps between genomic bins and the regions that defined functional genomic elements. Now we added another type of predictor created from each genomic element. This consisted of the distance from the center of each genomic bin to the center of the nearest region defining a genomic element as depicted in Figure X. To assess any improvement with the inclusion of these predictors we compared the performances of three multiple logistic regression models: one with only the overlap predictors, one with only the aforementioned distance predictors, and one with both.  It was found that the inclusion of distance predictors improved model performance.  Likewise, the model with both types of predictors futher improved model performance. As is common, with genomic data, the use of continuous predictors (especially with regards to distances) results in highly right skewed data with distances ranging from 0 to tens of thousands in base pairs. This can affect the convergence of likelihood maximization.

### Question 4: What normalization technique performed on the distance predictors best improves model performance?

Here, we considered three normalization techniques. The first was a simple $log_{2}$ transformation, in which one was added in the case of distances of 0. The second was an inverse hyperbolic sine tranformation given by $insert function here$ which has the benefit of handling values of 0. Lastly, an inverse normal tranformation was considered. The inverse normal transformation is a way of transforming the sample distribution of a continuous variable to make it appear more normally distributed by matching the normalized rank of the trait to a quantile in a normal distribution using the following formula $insert formula here$. Multiple logistic regression models were performed using data with each respective transformation and compared. It was found that the model with inverse normally transformed distance predictors not only out-performed the other transformation but also out-performed a model with no transformation at all. So far the only classification algorithm considered was a multiple logistic regression. However, given the large number possible functional genomic elements that can be considered, this model can be computationally inefficient. 

### Question 5: Which classification algorithm most accurately and efficiently identifies the genomic elements associated with TAD boundaries?

We compared the results from a multiple logistic regression model to that of a multiple logistic regression model with both LASSO and Elastic-Net regularization. Prior to model fitting, the predictors were standardized in order to compare magnitudes of the subsequent beta coefficients as a measure of variable importance. For the models with regularization, 10-fold cross validation was used to tune the penalization terms ($\lambda$ for LASSO and both $\lambda$ and $\alpha$ for Elastic-Net). Model performance was compared using F1-scores, MCCs, and AUROCs. The alpha level of significance was set at 0.05. All statistical analyses was performed in R version 3.4.2.



# RESULTS


There was a total of 247632 genomic bins that made up the response vector Y, 1629 (0.7%) of which contained TAD boundaries (Y=1). A total of 68 genomic features were included in the analysis. Two predictors were included for every feature (one binary, one continuous), making for a total of 136 predictors.  The list of predictors is provided in Table X. The feature space was reduced to 90 after all near-zero variance predictors were removed. The predictors that were removed are listed in Table X [??? Mark them in supplementary table of all features]. 

The best normalization technique was found to be the model that included a log base 2 transform with no standardized predictors. The AUC was found to be 0.809 and presented in Figure X. We see that this value is only marginally greater than the model using a log base 2 transform and standardized predictors. However, from Figure X, we see that the variable importance plot associated with a log base 2 transform with no standardized predictors (top right) yielded more accurate results than all other combinations. Notably, the insulator, CTCF, and DNaseI features are located in the top 3 most important features for predicting TAD boundaries, as expected. This is in contrast to the other three combinations, which presented conflicting results. Thus, it was concluded that only performing a log base 2 transformation was necessary. 

Figure X presents the model performance metrics of the eight different SMOTE combinations. The SMOTE combination utilizing percent over of 100 and percent under of 200 yielded the largest AUC (0.794). This was to be expected since this combination created perfectly balanced classes. However, looking at Figure X, the method using 100 bootstrap sample performed better than then model using SMOTE with an AUC of 0.809. Thus, it was concluded that using bootstrap samples would be more efficient moving forward. 

The best performing variable selection technique was found to be forward selection (AUC: 0.810) as shown in Figure X. All of the stepwise procedures performed better than the recursive feature elimination method, which not only performed worse, but also chose the most predictors. It should be noted that both forward and backward selection had the same AUC. However, the forward selection chose fewer predictors, 28 compared to 34 respectively. Thus, forward selection was chose as the most appropriate variable selection technique. Figure X presents the relationship between each variable selection technique. We see that there was significant agreement between forward and backward selections, with 26 predictors being shared by both. Likewise, there was a total of 12 predictors in common between all four techniques. Table X lists the common predictors between each comparison.

After the data was ran through our pipeline, the final dataset consisted of 28 log transformed predictors. Lastly, 100 bootstrap sampled random forest models were performed on said data. Figure X presents the results compared to the multiple logistic regression models proposed by Mourad et al. We see that the random forest model, using the pipeline processed data, preforms better compared to both models proposed by Mourad et al with an AUC of 0.805. Moreover, the variable importance plot in Figure X reiterates the strong predictive performance of the random forest model by indicating that the DNaseI, insulator, and CTCF genomic features are among the top 3 variables most predictive TAD boundaries. The MLR with LASSO estimation only marginally out performs the regular MLR model with AUCs of 0.750 and 0.747 respectively. Likewise, from Table X we can see that there is more similarity in the ranking of important features between the random forest model and the MLR with LASSO model. However, there is still a large disparity, with 12 variables recognized as important by the random forest that are missing from the MLR with LASSO model. Thus, we conclude that a random forest algorithm applied to a dataset ran through the proposed pipeline performs uniformly better than a multiple logistic regression model, regardless if LASSO estimation is used.


# DISCUSSION
