---
title: "Computational Prediction of Boundaries of 3D Genomic Domains in Class Imbalance Settings"
#csl: C:/Users/Spiro Stilianoudakis/Documents/TAD_predictive_modeling/Manuscript/styles.ref/genomebiology.csl
output: 
  word_document:
    #reference_docx: C:/Users/Spiro Stilianoudakis/Documents/TAD_predictive_modeling/Manuscript/styles.doc/NIH_grant_style.docx
bibliography: C:/Users/Spiro Stilianoudakis/Documents/TAD_predictive_modeling/Manuscript/References/references.bib
---

Spiro C. Stilianoudakis^1^ (stilianoudasc@mymail.vcu.edu), Mikhail G. Dozmorov^1\*^ (mikhail.dozmorov@vcuhealth.org)

^1^ Dept. of Biostatistics, Virginia Commonwealth University, Richmond, VA, 23298, USA  
^\*^ To whom correspondence should be addressed: Virginia Commonwealth University, Richmond, VA, 23298, 804-827-2055, mikhail.dozmorov@vcuhealth.org

# ABSTRACT

**Background.** Chromosome conformation capture sequencing technologies have shown that the three-dimensional (3D) structure of the genome is folded into distinct compartments, known as topologically associated domains (TADs) - units of coordinated gene expression. The location of TAD boundaries is highly conserved, suggesting the presence of epigenomic marks aiding in TAD formation. The ability to predict which epigenomic features are most associated with the TAD boundaries will allow to better understand the regulatory role of the 3D structure of the genome.

Existing methods for predicting associations between genomic elements tend to ignore key characteristics of the genomic data. Specifically, the number of TAD boundaries is much less than the number of other genomic regions, leading to heavily imbalanced classes. Furthermore, most methods utilize direct overlap as a means to quantify the association, while distance, the measure of spatial relationships, remains unaccounted for. Consequently, distances on a genomic scale vary widely, leaving uncertainty how the heavily right-tailed distribution of distance measures will affect the modelâ€™s performance.

**Methods.** We propose a novel data pre-processing pipeline that addresses those shortcomings. Lasso and Elastic Net were used for feature selection, coupled with five classifier methods. A number of classifier performance metrics were assessed, including the F1 measure and Matthew Correlation Coefficient (MCC), and area under the ROC curve (AUROC).

**Results.** Data preprocessing (log2-transformation and standardization) improves the performance of classification algorithms and allows for the ability to more accurately predict which genomic features are most associated with TAD boundaries. In contrast to overlap-based association measures, the distance between genomic elements was the most predictive measure. The random undersampling strategy addresses the class imbalance problem the most effectively in nearly all settings.

**Conclusions.** Current methods used to model the epigenomic features associated with TAD boundaries are insufficiently robust to handle properties of genomic data. Models applied to unprocessed data can have poor predictive performances. Focusing solely on standard performance assessment metrics, such as AUROC, can mask poor performance of the models; thus, the use of more balanced metrics, such as F1 and MCC, is warranted. Our model results in better performances and more accurate identification of important features associated with the formation of TAD boundaries.

# INTRODUCTION

The advent of various genome-wide sequencing technologies, such as high-throughput conformation capture (notably Hi-C), have revealed how the spatial organization of the human genome may affect several epigenetic functions [@lieberman2009comprehensive]. Analyses have shown that the genome is tightly compacted into distinct compartments.  There exist regions within these compartments that have been shown to be highly conserved and self-interacting, and termed topologically associating domains (TADs) [@dixon2012topological]. Evidence suggests that regulatory elements and genes tend to interact more frequently within the same TAD [@symmons2014functional]. This suggests that the boundaries of TADs may play a role in restricting the function of certain genomic elements such as enhancers, thereby impacting the transcription of genes. Furthermore, changing the 3D structure of the DNA, causing disruptions in these domains, can lead to adverse outcomes and diseases like cancer. Therefore, it has become increasingly important to be able to identify the key molecular drivers of the formation of TAD boundaries in order to further our understanding of the human genome.

The mechanisms underlying the formation of TADs are a complex and active area of research. Recently, it has been discovered that insulator sequences have a primary role in orchestrating the topological arrangements of higher-order chromatin architecture [@phillips2013chromatin]. Insulators are multi-faceted regulatory sequences that moderate a variety of genomic processes including activation, repression, and enhancer blocking. Specifically, the insulator binding protein CTCF has been found to be enriched at the boundary sequences of topologically associating domains in human cells and may therefore act as a mediator of long-range chromatin contacts [@zuin2014cohesin]. Other regulatory elements like particular histone modifications such as H3k36 and H3K27 trimethylation, and transcription factors such as ZNF274 and YY1 have been more frequently observed at TAD boundaries than in other regions [@rao20143d]. These have been found to be associated with more open chromatin which alter the accessibility of genes for transcription. The distinct patterns of different proteins and functional elements point toward the opportunity of using computational approaches in identifying which epigenomic features are most predictive of the development of TAD boundaries, allowing us to better understand what leads to their formation.

A study published by Mourad et al. used multiple logistic regression with LASSO regularization to predict TAD boundaries [@mourad2016computational]. They considered binning the genome at both 50 base and 1kb intervals and flanking TAD boundaries by 1kb and 20kb regions. The outcome Y was determined by whether or not a genomic bin overlapped with a flanked boundary. The feature space was obtained by considering the percent overlap between a bin and coordinates defining ChIP-seq peak data. Models were then evaluated using AUROC. However, a pervasive issue here becomes the introduction of highly imbalanced classes. Due to the sparcity of TADs throughout the genome, most bins will not overlap with a flanked TAD boundary. It is commonly agreed upon in the machine learning community that imbalanced datasets adversely impact the performance of the classifiers as the learned model is biased towards the majority class to minimize the overall error rate [@estabrooks2004multiple]. Similarly, careful consideration must also be taken when deciding which performance metric(s) to present when evaluating predictive models, especially in the case of imbalanced data. The popularity surrounding the use of ROC curves is that they do not depend on a threshold. However, when the prevalence of an event is low--that is, a genomic bin overlapping with a TAD boundary region--mean probabilities are biased towards the majority class. Likewise, metrics like accuracy and sensitivity and specificity do not incorporate the entirety of the confusion matrix created when validating predictive models on a test data set. Therefore, each of these metrics are likely to be inflated when evaluating model performance. 

In a similar study, Hong et al. used domain data from an hESC cell line to build a linear model and predict which genomic elements were associated with TAD boundaries [@hong2017computational]. They defined boundary segments as genomic regions before and after 150 kilobases of the boundary. To solve the imbalance problem, they randomly sampled from regions outside of the 150kb flank.  For their model, the feature space was determined by the number of counts of ChIP-seq peaks defining functional genomic elements that overlapped with the two segments. Individual models were then performed until the best model which included the concensus CTCF signal feature, followed by 10 additional elements was obtained. Here, however, it is likely that 1 iteration of random under-sampling will yield biased results, depending on how representative the under-sampled data is. Likewise, it is unclear how the performances of other balancing techniques compare (i.e. over-sampling or a combination of both under and over-sampling).

Furthermore, there are other aspects of TAD boundary modelling that current methods have failed to consider. Most notably is the concept of distance. As a feature engineering step, the use of distances (in base pairs) from genomic bins to regions of functional genomic elements has largely been ignored. However, these distance characteristics have the potential to offer a more accurate spatial representation of which genomic features are associated with TAD boundaries. Additionally, model performance is heavily contingent upon the resolution of the contact matrix used to identify the location of TADs throughout the genome. It is often unclear from authors of previous studies what resolution contact matrices were when retrieving TAD boundaries, and how other resolutions would affect their results. A larger resolution contact matrix will result in the identification of larger-sized TADs, and subsequently, less TAD boundary points. This will contribute to smaller sample sizes and could effect predictive performances.

In this study we have developed an ensemble framework that aims to address and compare a variety of data irregularities and characteristics that are associated with the prediction of TAD boundaries. We evaluated domain data obtained from four different resolution contact matrices for the GM12878 cell line including 5kb, 25kb, 50kb, and 100kb. For each resolution, we examined the inclusion of three different predictor types as the feature space for downstream modeling. We coupled each predictor type with two separate variable reduction techniques. Lastly, we performed a series of three different re-sampling techniques aimed at creating balanced classes. Random forest classification algorithms were performed to both compare each combination of the above ensemble, and investigate which functional genomic features were most associated with the formation of TAD boundaries.  Model performance was evaluated based on a total of four metrics which included test accuracy, area under the ROC curve (AUC), F1 score, and Matthew's Correlation Coefficient (MCC). 

#METHODS

##DOMAIN DATA

Replicate Hi-C data for the GM12878 cell line were downloaded from GEO GSE63525 (Experiments HIC001 to HIC029) [@rao20143d]. The chromosomal coordinates of topologically associating domains throughout the genome were obtained using the arrowhead algorithm from the Juicer toolbox provided by the Aiden Laboratory (https://github.com/aidenlab/juicer) [@durand2016juicebox]. Using the juicer toolbox, we were able to call TADs on 4 different contact matrix resolutions, which included 5 kb, 25 kb, 50 kb, and 100 kb. Identified TAD boundaries were represented by their location on the linear genome (hg19 human genome assembly), including start and end coordinates for chromosomes 1 through 22 (Figure 18 A). The start and end coordinates of all hierarchical TADs were concatenated, sorted, and unique boundary points representing the borders demarcating TADs were obtained (Figure 18 B). 

##MODEL CONSTRUCTION

To establish the data for modeling, the genome was binned into equally sized intervals (Figure 18 C). In order for a more systematic approach, the binning process was performed at the same resolution of the contact matrix that the domain data was obtained from. For example, for the domain data obtained from a 5kb resolution contact matrix, the genome was subsequently binned into 5kb intervals. The same processes was repeated for each of the other three resolutions. Again, operating systematically, we flanked the boundary coordinates on either side by a unit corresponding to the resolution of the particular domain data. For example, for the domain data obtained from a 5kb resolution contact matrix, each uniquely identified TAD boundary was flanked on either side by 5kb for a total width around each boundary point of 10kb. The same process was repeated for the other three resolutions. A genomic bin was labeled as having a TAD boundary within it (Y=1) if it overlapped with a particular flanked boundary. Otherwise, the bin was labeled as not containing a boundary (Y=0).

##GENOMIC ANNOTATIONS

Annotation data, in the form of functional genomic elements from ChIP-seq experiments were obtained from the Encyclopedia of DNA Elements (ENCODE) Consortium (Table 1). The annotations consisted of a variety of different chromatin states, histone marks, and DNase I hypersensitive sites. Each annotation was represented by their location throughout the genome via chromosomal coordinates.  

###FEATURE ENGINEERING USING GENOMIC ANNOTATIONS

Using the genomic elements, we created three types of predictors that were used as features to analyze their relationships with TAD boundaries in downstream modelling. The predictors consisted of two different types of overlaps, and a distance type. They are described in detail below:

   1.	Overlap Counts (OC): For each genomic bin, the total number of instances where a bin overlapped with regions representing a functional genomic element was calculated (Figure 2 A). In the case of no overlaps the value is given as 0.
   
   2.	Overlap Percent (OP): For each genomic bin, the percent overlap between the feature width and the total width of the bin was calculated (Figure 2 B). We defined the feature width as the number of base pairs that overlapped with the genomic bin. The percent was then calculated by dividing the feature width by the bin width. If multiple overlaps existed, the feature width was defined as the sum of the total number of base pairs that overlapped with a particular bin. Note that the bin width remained constant for a given resolution (either 5kb, 25kb, 50kb, or 100kb). Bins with no overlaps were given to be 0.

   3.	Distance: For each genomic bin, the distance (in base pairs) from the center of the bin to the center of the nearest region of a respective functional element was calculated (Figure 2 C).

##ENSEMBLE FRAMEWORK

An ensemble of models was established for the purposes of directly comparing the performances of different parameters in the framework. Each system in the framework is assumed to be composed of a model constructed from a particular data resolution, with a particular predictor type as the feature space. Details of each step in the framework are provided below. 

###TRAINING & TESTING SETS

The data set used for modeling was composed of the full set of genomic bins that either overlapped with a flanked TAD boundary or did not. These two classes made up the majority and minority sets (Figure 3 A). The data was then split into a 7:3 ratio of training to testing sets (Figure 3 B). Each training and testing set was composed of a similar majority to minority class ratio as the full data set (Figure 3 C). The training set was then used to perform all downstream modeling.

###VARIABLE REDUCTION

We evaluated the use of two variable reduction algorithms, the LASSO and Elastic-Net regularizations (Figure 3 D). Each algorithm was performed prior to re-sampling. For the LASSO, the $\lambda$ penalization term was tuned over a grid of 10 values on an exponential scale ranging from 0.01 to 10. The additional $\alpha$ term for the Elastic-Net was tuned over 10 equa-distant values from 0 to 1.

###RE-SAMPLING TECHNIQUES

We then evaluated three re-sampling techniques (in addition to no re-sampling) used to create balanced classes (Figure 3 E). They are detailed below:

   1.	No Sampling: All of the data points from the majority and minority class of the training set were used.

   2.	Random Under-Sampling (RUS): All of the minority classes from the training set were used. A random set without replacement from the majority classes of the training set were used to match the number of minority samples. In this paper we performed 50 iterations of random under-sampling. At each iteration a random forest classification algorithm was performed. Performance metrics were aggregated by taking the average across all of the iterations.

   3.	Random Over-Sampling (ROS): All of the majority classes from the training set were used. A random set with replacement from the minority classes of the training set were used to match the number of majority samples. Similar to the under-sampling technique, 50 iterations were performed and results were aggregated by taking the average across iterations.

   4.	SMOTE (Synthetic Minority Over-Sampling Technique): This method incorporated both random under- and over-sampling. Under-sampling is performed without replacement from the majority class, while over-sampling is performed by creating new synthetic observations using the minority class. The SMOTE algorithm is stored in the DMwR package, available in R [@chawla2002smote]. The user is able to specify the parameters denoting the percent of over- and under-sampling from the two classes. This allows the user to control the proportion of disbalance in the data. For the purposes of this paper, we used SMOTE to create perfectly balanced data. 

###CLASSIFICATION

A classification algorithm in the form of a random forest was performed and validated using the same test set for all models in the ensemble (Figure 3 F). 10-fold cross validation was used to reduced bias due to random dataset generation. The default number of features to consider at each node of the random forest algorithm was set as the square root of the number of features in the model. Likewise, the number of ensemble trees to aggregate was set at 500. Once the model was implemented, it was assessed using the test set, and performance metrics were then recorded. 

Using set notation the formulation of the ensemble framework can be defined as follows:

Set of different resolutions:

R = {5kb, 25kb, 50kb, 100kb}

Set of Predictor Types:

P = {OC, OP, Distance}

Set of Variable Reduction Techniques:

V = {LASSO, Elastic-Net}

Set of Class-Balancing Methods:

C = {None, RUS, ROS, SMOTE}

Therefore, a system produced from the ensemble framework is defined as follows:

E = {r, p, v, c}, where r $\in$ R, p $\in$ P, v $\in$ V, and c $\in$ C.

Once a system was defined, a random forest algorithm was performed. Letting |X| denote the cardinality of each set, then we evaluated |R| x |P| x |V| x |C| different ensemble systems in this paper.

###MODEL EVALUATION & PREDICTION

The efficacy of different ensemble systems was compared using various performance metrics including accuracy, AUC, F1-score, and MCC. These metrics are defined as follows:

$$
\begin{equation}
\begin{aligned}
Accuracy &= \dfrac{TP + TN}{TP + TN + FP + FN} \\
F1 - Score &= \dfrac{2TP}{2TP + FP + FN} \\
MCC &= \dfrac{TP \times TN - FP \times FN}{\sqrt{ (TP + FP)(TP+FN)(TN+FP)(TN+FN) }}
\end{aligned}
\end{equation}
$$
Here, TP refers to the number of bins correctly identified as containing a TAD boundary (true positives), FP refers to the number of bins incorrectly identified as containing a TAD boundary (false positives), TN refers to the number of bins correctly identified as not containing a TAD boundary (true negatives), and FN refers to the number of bins incorrectly identified as not containing a TAD boundary. Each of these quantities are obtained from the confusion matrix created by validating the model on the testing set.  We also considered the AUC for each model by computing the average trapezoidal approximations for the curve created by the true positive rates (TPR) and false positive rates (FPR).

For the task of identifying the functional genomic elements that were most predictive of the formation of TAD boundaries, we evaluated the variable importances associated with each predictor of the random forest model. For each tree, the prediction accuracy on the out-of-bag portion of the data is recorded. Then the same is done after permuting each predictor variable. The difference between the two accuracies are then averaged over all trees, and normalized by the standard error [@kuhn2012caret]. 

#RESULTS

##ENSEMBLE COMPARISONS

In this section we provide the details of the comprehensive experiments performed in order to assess each ensemble system. We evaluated and compared 4 domain data sets, 3 predictor types, 2 variable reduction techniques, and 4 class balancing techniques. Thus, we generated 96 (=4 $\times$ 3 $\times$ 2 $\times$ 4) separate models. For simplicity, we have only presented the most significant results. Results of the complete ensemble are available in the Supplementary Materials.

###CLASS DISTRIBUTIONS ACROSS RESOLUTIONS

The coordinates of the corresponding 5kb resolution contact maps resulted in a total of 44948 genomic bins (Table 2). There were only 3083 bins that overlapped with a flanked TAD boundary (6.9%). An increase in resolution resulted in less genomic bins and a slighly less degree of class imbalance (Supplementaty Table 8). The overall average perentage of class imbalance across all data resolutions was 13.2%.  After applying each resampling technique to the training sets for each data resolution, we obtained perfectly balanced classes (Figure 4). That is, the ratio of bins that overlapped with flanked TAD boundaries to bins that did not was 1:1.

###CLASS IMBALANCE HINDERS PERFORMANCE

We first compared models with either overlap counts or overlap percent predictor types, from the 5kb resolution data (Figure 12). These results were from random forest models fit to data without any re-sampling, using either LASSO or Elastic-Net regulariations. We found that differences in performances across variable reduction techniques were marginal. More importantly, when evaluating model performance using accuracy or AUC, the model appeared to perform relatively well. At second glance, however, when considering both the F1-score and MCC, we were able to assess just how poorly the model was performing (Supplementary Table 9). 

The performances were found to be consistently poor for models with no re-sampling across the other resolutions (Supplementary Figure 13; Supplementary Table 10). The low, and sometimes missing, values indicated that the model was unable to identify many, if any, true positive outcomes. That is, given imbalanced data, the model was unable to predict which genomic bins truly overlapped with a flanked TAD boundary.

###RANDOM UNDER-SAMPLING IMPROVES MODEL PERFORMANCE

When evaluatating the 5kb resolution data for a randomly under-sampled training set, it was found that models obtained better classification performance for F1 and MCC metrics (Figure 14). The increase in performance was present across both overlap predictor types. Models also featured a decrease in both accuracy and AUC, which was attributed to less inflated false negative rates (Supplementary Table 11). Variable reduction was found not to have an affect on resampling, and subsequent performances, as any differences were again marginal. Performances were also improved among the models using the other data resolutions as well. However, we found that model improvement dissipated as resolution increased (Supplementary Figure 15; Supplementary Table 12).

###DISTANCE TYPE PREDICTORS OUT-PERFORM OTHER PREDICTOR TYPES

We then used the ensemble to compare models with distance type predictors for the feature space. For the 5kb resolution data, it was found that models with distance type predictors out performed models with either of the two overlap types, regardless of the regularization technique performed (Figure 16). The improvement was observed across all 4 performance metrics that were considered (Supplementary Table 13). Likewise, improved performances were seen in the other 3 resolutions as well. Although overall performance decreased as resolution increased, models with distance type predictors still were able to maintain a profound improvement (Supplementary Figure 14; Supplementary Table 14).

###PERFORMANCES DEGRADE AS RESOLUTION INCREASES

Finally, we directly compared the performances of models across the different resolutions. The comparisons consisted of random forest models using distance type predictors, elastic-net regularization, and 50 iterations of random under-sampling. The model using 5kb resolution domain data was found to perform slightly better compared to the 25kb and 50kb resolutions (Figure 9). A sharp decrease in performance was seen in the 100kb resolution. 

The differences in performances was most evident when comparing the variable importances across the 4 resolutions. We found that for the 5kb resolution, the most predictive elements included insulator proteins, DNase hypersensitive sites, the transcription factor CTCF, as well as histone modifications H3k9ac, H2az, and H3k4me2 (Figure 10 A). Although, the insulator protein is featured as a top predictor in 2 of the other 3 resolutions, the rest of the predictors were less consistent among each other and less in agreement with the literature (Figure 10 B-D). The results from Figures 9 and 10 confirm that the model results appear to degrade as resolution increases with respect to both prediction and the identification of genomic elements associated with TAD boundaries.


#Discussion



# Abbreviations



# Acknowledgements

_Conflict of Interest._ None.

# Funding



# Tables

# Figures

# Table Legends

## Table 1: List of Genomic Annoations. 

The full list of genomic annotations used in downstream analyses. These annotations were the functional genomic elements used to predict the formation of TAD boundaries. They were obtained via ChIP-Seq experiments, mapped to human genome assembly hg19, and made available by the ENCODE Consortium.

## Table 2: Class Distributions

Summary of the class distributions for each re-sampling technique, across each resolution. All re-sampling techniques yielded completely balanced classes. That is, there was a 1:1 relationship between the majority and minority classes after sampling took place.

## Table 7: Model Performances at all Resolutions

Performance metrics comparing models using different sampling approaches for each of the 4 resolutions. Withing each resolution, the best value in each column for each performance metric is underlined to compare different sampling approaches, while the highest value in each row is highlighted in bold to compare different predictor types. 


# Figure legends

## Figure 1: Model Construction

Diagram of the model construction used for downstream analysis. The linear genome was binned according to the resolution of the respective HiC experiment (either 5kb, 25kb, 50kb, or 100kb intervals). TAD boundaries were then flanked by 1-unit on either side of the boundary point. The unit flanking was indicative of the resolution that the domain data was obtained from (i.e. for 5kb resolution, 1 unit represents 5kb for a total flanking region of 10kb). The response vector Y used for classification was determined by whether or not a genomic bin overlapped with a flanked region. The positional coordinates of each functional genomic element, obtained from ENCODE, were then used to define the feature space of the models.

## Figure 2: Predictor Types 

Diagram of the 3 predictor types considered when assessing the relationship between TAD boundaries and functional genomic elements. Each predictor type was used as the feature space in downstream analyses for predicting which functional genomic elements were associated with the formation of TAD boundaries. Featured above are bin-specific examples of the construction of each predictor type. (Left) The overlap count (OC) predictors were calculated by considering the total number of elemental regions that overlapped with each genomic bin. (Middle) The overlap percent (OP) predictors were calculated by dividing the sum of all feature widths within each specific bin and dividing by the total bin width (either 5, 25, 50, or 100 kilobases given resolution of boundary data). (Right) The distance predictors were calculated by measuring the distance (in base pairs) from the center of each genomic bin to the center of the nearest elemental region of interest. The two green segments directly below the rightmost enlarged figure represent the center of the overlapping regions defining the respective functional genomic element.

## Figure 3: Ensemble Framework/Model Building Pipeline

A diagram of the model building pipeline given an a combination of inputs from the ensemble framework. The data was split into a 7:3 training set to testing set ratio, the variable reduction technique of choice was implemented, and a random forest classification algorithm was performed. Each model was then validated on the same testing set. 

## Figure 4: Class Imbalance

Barplots illustrating the class imbalance problem featured across each of the four different resolutions that were analyzed. Minority classes represent the number of genomic bins that contain a TAD boundary, while the majority classes represent the number of genomic bins that do not contain a TAD boundary. 

## Figure 11: Model Performances for all Resolutions

Comparing model performances for TAD boundary data for all 4 resolutions. The four regions represent (from left to right; top to bottom) data at 5kb, 25kb, 50kb, and 100kb resolutions. Within each region, the rows represent the set of re-sampling techniques, while the columns represent the set of performance metrics that the models were evaluated on. Each plot compares 2 sets of models; one using LASSO regularization and one using Elastic-Net regularization. Within each set, each bar represents the performance of a model with a specific predictor type; either overlap counts (OC) in red, overlap percent (OP) in green, or distance in blue. 

## Figure 9: Comparing Performances

Comparing performances of random forest classification algorithms, across TAD boundary data at each resolution for models using distance-type predictors, with elastic-net regularization and random under-sampling. Performances were aggregated by taking the average of each metric across 50 iterations of random under-sampling.

## Figure 10: Comparing Variable Importances

Variable importance plots for the top 15 most predictive functional genomic elements for each of the 4 different resolutions. The x-axis represents the standardized difference between the out-of-bag prediction accuracy after permuting each predictor variable, averaged across all trees. The greater the mean standardized difference, the more importance the predictor is to the model.


# Supplementary Tables and Figures


# Supplementary Legends


# References


