# Notes on TAD prediction and enrichment

## TAD predictions

- Schreiber, Jacob, Timothy J Durham, Jeffrey Bilmes, and William Stafford Noble. “Multi-Scale Deep Tensor Factorization Learns a Latent Representation of the Human Epigenome,” July 8, 2018. https://doi.org/10.1101/364976. - Avocado - cell type-specific epigenome representation using a deep neural network tensor factorization method. Predict gene expression, promoter-enhancer interactions, TAD boundaries, frequently interacting regions (FIREs), missing cell-specific epigenomic marks. Comparison with ChromImpute, PREDICTD. Improves PREDICTD by inserting a deep neural network to nonlinearly combine decomposed latent factors. Model, imputed marks can be downloaded at https://noble.gs.washington.edu/proj/avocado/. Data source: TAD boundaries and FIRE scores are from supplementary of A. D. Schmitt, M. Hu, I. Jung, Z. Xu, Y. Qiu, C. L. Tan, Y. Li, S. Lin, Y. Lin, C. L. Barr, and B. Ren. A compendium of chromatin contact maps reveals spatially active regions in the human genome. Cell Reports, 17:2042–2059, 2016. Promoter-enhancer interactions are from https://github.com/shwhalen/targetfinder/tree/master/paper/targetfinder/combined/output-epw

- Hong, Seungpyo, and Dongsup Kim. “Computational Characterization of Chromatin Domain Boundary-Associated Genomic Elements.” Nucleic Acids Research 45, no. 18 (October 13, 2017): 10403–14. https://doi.org/10.1093/nar/gkx738. - Feature selection for predicting TAD boundaries. In addition to CTCF, ZNF143, YY1, DNAse, H3K36me3, TSSs, RNA Pol II, SP1, ZNF274, SIX5. Linear model, similar to forward selection. Data from UCSC, in supplementary. Distinguishing boundaries and centers. Distinguishing cell type-specific and clustered TFBSs.

- Mourad, Raphaël, and Olivier Cuvier. “Computational Identification of Genomic Features That Influence 3D Chromatin Domain Formation.” Edited by Kai Tan. PLOS Computational Biology 12, no. 5 (May 20, 2016): e1004908. https://doi.org/10.1371/journal.pcbi.1004908. - Predicting TAD boundaries from transcription factor binding sites (TFBSs). Multiple logistic regression with lasso L1 penalization, allows for interactions, positive/negative effect. Outperforms enrichment test, random forest (https://github.com/aloysius-lim/bigrf). For humans, CTCF, Cohesin, ZNF134, Polycomb group proteins are positive predictors, P300, RXRA, BCL11A and ELK1 are negative predictors. Tested for the effect of SNPs in CTCF binding sites (SNPs destroy TAD boundaries), the effect of slightly imprecise boundaries. Hi-C bins are assigned 1/0 for overlapping/nonoverlapping TFBSs, or % overlap if it is partial. No mentioning class disbalance problem, no cross-validation, no explicit distance consideration, no histone marks. HiCfeat R package, https://sites.google.com/site/raphaelmouradeng/home/programs

- Sefer, Emre, and Carl Kingsford. “Semi-Nonparametric Modeling of Topological Domain Formation from Epigenetic Data.” In Algorithms in Bioinformatics, edited by Mihai Pop and Hélène Touzet, 9289:148–61. Berlin, Heidelberg: Springer Berlin Heidelberg, 2015. https://doi.org/10.1007/978-3-662-48221-6_11. - Non-parametric approach, called nTDP, based on Bernstein polynomials for modeling TADs from histone modifications. Intro about histone modifications enriched in TAD boundaries (H3K4me3 and H3K27ac). Math, statistics, assumptions, regularization. Parameters of the model should be estimated via training, Cross-validation to prevent overfitting. Hi-C data from Human IMR90, ES, mouse ES. Binning ChIP-seq and DNAse-seq data at 40kb resolution as log RPKMs, consensus TAD boundaries from Armatus. The sets of 4 and 6 modifications that were most informative are: {H3K36me3, H3K4me1, H3K4me3, H3K9me3} and {H3K4me3, H3K79me2, H3K27ac, H3K9me3, H3K36me3, H4K20me1}. chromatin states from Segway are not important. https://www.cs.cmu.edu/~ckingsf/research/ntdp/

- Bednarz, Paweł, and Bartek Wilczyński. “Supervised Learning Method for Predicting Chromatin Boundary Associated Insulator Elements.” Journal of Bioinformatics and Computational Biology 12, no. 06 (December 2014): 1442006. https://doi.org/10.1142/S0219720014420062. - Predicting TAD boundaries using training data, and making new predictions. Bayesian network (BNFinder method), random forest vs. basic k-means clustering, ChromHMM, cdBEST. Using sequence k-mers and ChIP-seq data from modENCODE for prediction - CTCF ChIP-seq performs best. Used Boruta package for feature selection. Bayesian network performs best. To read on their BNFinder method

- Huang, Jialiang, Eugenio Marco, Luca Pinello, and Guo-Cheng Yuan. “Predicting Chromatin Organization Using Histone Marks.” Genome Biology 16, no. 1 (December 2015). https://doi.org/10.1186/s13059-015-0740-z. - Predicting chromatin interaction hubs and TAD boundaries from Hi-C data and 9 histone marks using BART - Bayesian Additive Regression Trees. Rank chromatin interactions into high ("hubs"), median, low, non-significant. Hubs are enriched in GWAS SNPs. Hubs are enriched in and predicted by H3K4me1, H3K27ac (markers of enhancers) in the center. Conservation, GC content, distance  to TSS did NOT improve predictions. The model trained using one cell type data predicts hubs in another. TAD boundaries from IMR90 (Dixon) vs. non-boundary genomic loci with similar interaction frequency. CTCF, then negative H3K4me1, are the most predictive, but H3K4me3 is the second most enriched.

- Zhou, Jian, and Olga G. Troyanskaya. “Global Quantitative Modeling of Chromatin Factor Interactions.” Edited by Andrey Rzhetsky. PLoS Computational Biology 10, no. 3 (March 27, 2014): e1003525. https://doi.org/10.1371/journal.pcbi.1003525. - A novel maximum entropy-based modeling approach to quantitatively capture interactions between chromatin factors at the same genomic location. Choosing the most uniform/least structured, maximum entropy. Pairwise and triplet interactions. L1 regularization.

- Bednarz, Paweł, and Bartek Wilczyński. “Supervised Learning Method for Predicting Chromatin Boundary Associated Insulator Elements.” Journal of Bioinformatics and Computational Biology 12, no. 6 (December 2014): 1442006. https://doi.org/10.1142/S0219720014420062. - Prediction of TAD boundaries in Drosophila using modENCODE data (>30 ChIP-Chip and ChIP-seq tracks). Starting from k-means, then Hidden Markov Models, then use cdBEST and BMFinder previously published methods. ROC curves. Boruta package for feature prioritization. Prediction of new boundaries.


## TAD epigenomics

- Yan, Koon-Kiu, Shaoke Lou, and Mark Gerstein. “MrTADFinder: A Network Modularity Based Approach to Identify Topologically Associating Domains in Multiple Resolutions.” PLoS Computational Biology 13, no. 7 (July 2017): e1005647. https://doi.org/10.1371/journal.pcbi.1005647. - MrTADFinder - network modularity-based TAD finder, community detection. Adapted for multiple resolutions with parameter y. Distance-dependent model. Optimization framework, Louvain algorithm to optimize Q. Confirmed Dixon's observations of H3K4me3, H3K27ac enrichment at TAD boundaries, depletion of H3K9me3, H3K27me3 enriched across resolutions. Genes, especially, housekeeping, are enriched near TAD boundaries. High- and extreme occupancy target regions (TF binding) are also enriched. CTCF enrichment is general. Logistic regression to predict TAD boundaries from TFBSs, prioritize which TFs are most important, Refs 18 and 19 refer to similar work. https://github.com/gersteinlab/MrTADFinder


## Epigenomic predictions

Many other in my `Zotero/Genome/Sequencing/Epigenomics/machine learning` collection

- Yang, Yang, Ruochi Zhang, Shashank Singh, and Jian Ma. “Exploiting Sequence-Based Features for Predicting Enhancer-Promoter Interactions.” Bioinformatics (Oxford, England) 33, no. 14 (July 15, 2017): i252–60. https://doi.org/10.1093/bioinformatics/btx257. - Predicting enhancer-promoter interactions based on sequence only. Boosted tree ensemble model. Two ways: PEP-Motif (prediction from motifs detected in the sequences), and PEP-Word (word embedding model, achieved better performance). Compared with RIPPLE and TargetFinder. https://github.com/ma-compbio/PEP

- Cao, Qin, Christine Anyansi, Xihao Hu, Liangliang Xu, Lei Xiong, Wenshu Tang, Myth T. S. Mok, et al. “Reconstruction of Enhancer-Target Networks in 935 Samples of Human Primary Cells, Tissues and Cell Lines.” Nature Genetics 49, no. 10 (October 2017): 1428–36. https://doi.org/10.1038/ng.3950. - Enhancer-promoter prediction from cell-specific gene expression, methylation in windows around TSS, Roadmap, FANTOM5 CAGE, ENCODE DNAse, LASSO, Elastic Net, cross-validation. 935 cell lines, networks downloadable as cell-specific hg19 genomic coordinates-EnsemblIDs-confidence score (higher the better) (http://yiplab.cse.cuhk.edu.hk/jeme/). Activity of _multiple_ enhancers explains gene expression better. JEME method outperforms TargetFinder, PreSTIGE, Ripple, IM-PET, Ernst. Activity is confined within TADs. Depletion of CTCF between enhander-TSS pair. Closest enhancer is poor predictor of gene regulation, distance is the second best predictor, combined model is the best. JEME code https://github.com/yiplabcuhk/JEME

- Firpi, Hiram A., Duygu Ucar, and Kai Tan. “Discover Regulatory DNA Elements Using Chromatin Signatures and Artificial Neural Network.” Bioinformatics (Oxford, England) 26, no. 13 (July 1, 2010): 1579–86. https://doi.org/10.1093/bioinformatics/btq248.  -Predicting enhancers from histone marks using a time-delay neural network. Review of other prediction approaches. Genomic annotations are converted into two functions - mean and energy, used for predictions. Fisher discriminant analysis as a feature extraction/reduction technique (H3K4me1 is the most predictive, then H3K4me2, H3K4me3)

- He, Bing, Changya Chen, Li Teng, and Kai Tan. “Global View of Enhancer-Promoter Interactome in Human Cells.” Proceedings of the National Academy of Sciences of the United States of America 111, no. 21 (May 27, 2014): E2191-2199. https://doi.org/10.1073/pnas.1320308111. - IM-PET method. Enhancer-promoter interaction prediction from several features: enhancer-promoter activity profile correlation, TF-promoter correlation, enhancer-promoter coevolution, distance between enhancer and promoter. DISTANCE is the most important predictive feature, but helped by others. Random forest, SVM and logistic regression perform worse. Compared with four other methods (nearest promoter, PreSTIGE, Ernst, Thurman). Cross-validation, no overfitting. Enhancer-promoter interactions are more cell-type-specific than just enhancers. 

- Schuster-Böckler, Benjamin, and Ben Lehner. “Chromatin Organization Is a Major Influence on Regional Mutation Rates in Human Cancer Cells.” Nature 488, no. 7412 (August 23, 2012): 504–7. https://doi.org/10.1038/nature11273. - Cancer SNP density correlates with H3K9me3. 46 features, including Hi-C PCs, were tested for pairwise Pearson correlations.

## Prediction, general

- Bekkar, Mohamed, Hassiba Kheliouane Djemaa, and Taklit Akrouf Alitouche. "Evaluation measures for models assessment over imbalanced datasets." Iournal Of Information Engineering and Applications 3.10 (2013).  - List of various prediction metrics to use for imbalanced data and descriptions of each

- Whalen, Sean, Rebecca M. Truty, and Katherine S. Pollard. “Enhancer-Promoter Interactions Are Encoded by Complex Genomic Signatures on Looping Chromatin.” Nature Genetics 48, no. 5 (May 2016): 488–96. https://doi.org/10.1038/ng.3539.  -TargetFinder - ensemble learning of enhancer-promoter interactions within TADs using epigenomic data (DNAse hypersensitive sites, methylation, gene expression, TFBSs, conservation). Multiple machine learning techniques, applied to multiple cell types to learn shared and unique characteristics, as well to the combined cell line data modeled by epigenomic data common to the combined cell lines. Methylation, elongation histone modifications, AP-1 binding are best predictive features, not genes or conservation. Near optimal performance using 16 features. Importance of proximal features (distance). Introduction and discussion about previous use of epigenomic machine learning. https://github.com/shwhalen/targetfinder
- Xi, Wang, and Michael A Beer. “Local Epigenomic State Cannot Discriminate Interacting and Non-Interacting Enhancer-Promoter Pairs with High Accuracy,” October 25, 2018. https://doi.org/10.1101/420372. - Overfitting in epigenomics machine learning due to class imbalance. TargetFinder reanalysis. Gradient boosting, but not SVM, achieved good performance.

- Lu, Wei, Zhe Li, and Jinghui Chu. “Adaptive Ensemble Undersampling-Boost: A Novel Learning Framework for Imbalanced Data.” Journal of Systems and Software 132 (October 2017): 272–82. https://doi.org/10.1016/j.jss.2017.07.006. - Class imbalance problem, proposed the Ensemble of Undersampling (EUS) technique in combination with Real (in contrast to Discrete) Adaboost, cost-sensitive weighting, and adaptive boundary decision strategy. Introduction to the problem, references to existing methods. Tested on 18 datasets from KEEL repository, performance measured using AUC and other metrics.

- Dubey, Rashmi, Jiayu Zhou, Yalin Wang, Paul M. Thompson, Jieping Ye, and Alzheimer’s Disease Neuroimaging Initiative. “Analysis of Sampling Techniques for Imbalanced Data: An n = 648 ADNI Study.” NeuroImage 87 (February 15, 2014): 220–41. https://doi.org/10.1016/j.neuroimage.2013.10.005. - Class imbalance testing. Various sampling techniques (over-/undersampling, SMOTE), six feature selection algorithms, ensemble feature selection using RF and SVM. K-medoids undersampling is optimal. Description of existing approaches. Systematic framework to evaluate various combinations of F (feature selections algorithms) x S (set of class-imbalance handling approaches) x C ( classifiers). k-fold cross-validation to avoid bias due to random sampling.

- Blagus, Rok, and Lara Lusa. “SMOTE for High-Dimensional Class-Imbalanced Data.” BMC Bioinformatics 14, no. 1 (2013): 106. https://doi.org/10.1186/1471-2105-14-106. - SMOTE theoretical and empirical benchmarking. Inferior for high-dimensional data than undersampling. Class imbalance is most problematic in high-dimensional data. Variable reduction is needed before classification (ref 37). 

- Lunardon, Nicola, Giovanna Menardi, and Nicola Torelli. “ROSE: A Package for Binary Imbalanced Learning.” R Journal 6, no. 1 (2014). - ROSE - R package for over-/undersampling. Menardi and Torelli reference to read. https://cran.r-project.org/web/packages/ROSE/index.html

- Zhang, Ruochi, Yuchuan Wang, Yang Yang, Yang Zhang, and Jian Ma. “Predicting CTCF-Mediated Chromatin Loops Using CTCF-MP.” Bioinformatics 34, no. 13 (July 1, 2018): i133–41. https://doi.org/10.1093/bioinformatics/bty248. - CTCF-MP - boosted tree classifier for loop prediction from sequence-level features (word2vec, deep autoencoder to compress the 200-dimensional space to 32 dimensions, then tSNE mapping to 2D), CTCF ChIP-seq and DNAse-seq data. Convergent CTCF sites are important. Best prediction of common loops, little worse cell-type-specific. Imbalanced dataset performed well. https://github.com/ma-compbio/CTCF-MP

- Wong, Kin Yau, Cheng Fan, Maki Tanioka, Joe S. Parker, Andrew B. Nobel, Donglin Zeng, Dan-Yu Lin, and Charles M. Perou. “An Integrative Boosting Approach for Predicting Survival Time With Multiple Genomics Platforms,” June 4, 2018. https://doi.org/10.1101/338145. - Survival analysis using integrative approach - multiple data types (clinical, gene/protein expression, gene signatures) and methods (LASSO, elastic net, boosting using cross-validation and permutation). Good example of presenting comparison of methods on a biological problem.

- Mayr, A., H. Binder, O. Gefeller, and M. Schmid. “The Evolution of Boosting Algorithms. From Machine Learning to Statistical Modelling.” Methods of Information in Medicine 53, no. 6 (2014): 419–27. https://doi.org/10.3414/ME13-01-0122. - Boosting, part 1. AdaBoost, algorithm, overfitting and resistance to it, connection to generalized additive model (GAM). Likelihood-based boosting. Early stopping as a way to prevent overfitting. R packages mboost, gbm, GAMBoost, CoxBoost

- Haibo He, Yang Bai, Edwardo A. Garcia, and Shutao Li. “ADASYN: Adaptive Synthetic Sampling Approach for Imbalanced Learning,” 1322–28. IEEE, 2008. https://doi.org/10.1109/IJCNN.2008.4633969. - ADASYN - adaptive synthetic sampling approach. Overview of current methodologies - sampling strategies, synthetic data generation (SMOTE), others. Comparison with others. Open question - how much imbalance hurt learning? Important - categorical variables are excluded. https://cran.r-project.org/web/packages/smotefamily/

- Turki, Turki, and Zhi Wei. “Boosting Support Vector Machines for Cancer Discrimination Tasks.” Computers in Biology and Medicine 101 (October 1, 2018): 236–49. https://doi.org/10.1016/j.compbiomed.2018.08.006. - Boosting SVM outperforms regular SVM and xgboost. Three versions of the algorithm. Tested on cancer datasets. An example which metrics to use for classifier performance evaluation, and how to describe and present the results in tables (figures are bad).

- Drummond, Chris, Robert C Holte, and others. “C4. 5, Class Imbalance, and Cost Sensitivity: Why under-Sampling Beats over-Sampling.” In Workshop on Learning from Imbalanced Datasets II, 11:1–8, 2003. - a reference demonstrating that undersampling is better than oversampling in class imbalance problem

